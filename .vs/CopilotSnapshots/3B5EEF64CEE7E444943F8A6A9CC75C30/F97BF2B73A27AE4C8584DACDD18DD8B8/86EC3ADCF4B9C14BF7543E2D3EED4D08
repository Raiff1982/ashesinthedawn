import React, {
  createContext,
  useContext,
  useState,
  useEffect,
  useRef,
  useMemo,
} from "react";
import type {
  Track,
  Project,
  LogicCoreMode,
  Plugin,
  Marker,
  LoopRegion,
  MetronomeSettings,
  Bus,
  MidiDevice,
  MidiRoute,
  AudioContextState,
} from "@/types";
import { getAudioEngine } from "../lib/audioEngine";
import { getCodetteBridge, CodetteSuggestion } from "../lib/codetteBridge";
import { setDAWContext } from "../lib/actions/initializeActions";
import { supabase } from "../lib/supabase";
import {
  saveProjectToStorage,
  loadProjectFromStorage,
  clearProjectStorage,
  createAutoSaveInterval,
} from "../lib/projectStorage";
import {
  downloadProjectFile,
  importProjectFromFile,
  openFileDialog,
} from "../lib/projectImportExport";
import {
  getEffectChainManager,
  TrackEffectChain,
  EffectInstanceState,
} from "../lib/trackEffectChainManager";
import { useEffectChain } from "../hooks/useEffectChain";

interface DAWContextType {
  currentProject: Project | null;
  tracks: Track[];
  selectedTrack: Track | null;
  isPlaying: boolean;
  isRecording: boolean;
  currentTime: number;
  zoom: number;
  logicCoreMode: LogicCoreMode;
  voiceControlActive: boolean;
  cpuUsage: number;
  isUploadingFile: boolean;
  uploadError: string | null;
  deletedTracks: Track[]; // Trash
  canUndo: boolean;
  canRedo: boolean;
  markers: Marker[];
  loopRegion: LoopRegion;
  metronomeSettings: MetronomeSettings;
  inputLevel: number;
  latencyMs: number;
  bufferUnderruns: number;
  bufferOverruns: number;
  isAudioIOActive: boolean;
  audioIOError: string | null;
  selectedInputDevice: { label: string } | null;
  selectedInputDeviceId: string | null;
  selectedOutputDeviceId: string | null;
  selectInputDevice: (deviceId: string) => Promise<void>;
  selectOutputDevice: (deviceId: string) => Promise<void>;
  getAudioContextStatus: () => AudioContextState | string;
  setCurrentProject: (project: Project | null) => void;
  addTrack: (type: Track["type"]) => void;
  selectTrack: (trackId: string) => void;
  updateTrack: (trackId: string, updates: Partial<Track>) => void;
  deleteTrack: (trackId: string) => void; // Soft delete to trash
  duplicateTrack: (trackId: string) => Promise<Track | null>;
  restoreTrack: (trackId: string) => void; // Restore from trash
  permanentlyDeleteTrack: (trackId: string) => void; // Hard delete
  togglePlay: () => void;
  toggleRecord: () => void;
  stop: () => void;
  setLogicCoreMode: (mode: LogicCoreMode) => void;
  toggleVoiceControl: () => void;
  saveProject: () => Promise<void>;
  loadProject: (projectId: string) => Promise<void>;
  uploadAudioFile: (file: File) => Promise<boolean>;
  getWaveformData: (trackId: string) => number[];
  getAudioDuration: (trackId: string) => number;
  getAudioBufferData: (trackId: string) => Float32Array | null;
  getAudioLevels: () => Uint8Array | null;
  seek: (timeSeconds: number) => void;
  setTrackInputGain: (trackId: string, gainDb: number) => void;
  addPluginToTrack: (trackId: string, plugin: Plugin) => void;
  removePluginFromTrack: (trackId: string, pluginId: string) => void;
  togglePluginEnabled: (
    trackId: string,
    pluginId: string,
    enabled: boolean
  ) => void;
  undo: () => void;
  redo: () => void;
  // Phase 3: Markers
  addMarker: (time: number, name: string) => void;
  deleteMarker: (markerId: string) => void;
  updateMarker: (markerId: string, updates: Partial<Marker>) => void;
  // Phase 3: Looping
  setLoopRegion: (startTime: number, endTime: number) => void;
  toggleLoop: () => void;
  clearLoopRegion: () => void;
  // Phase 3: Metronome
  toggleMetronome: () => void;
  setMetronomeVolume: (volume: number) => void;
  setMetronomeBeatSound: (sound: MetronomeSettings["beatSound"]) => void;
  // Modal State
  showNewProjectModal: boolean;
  openNewProjectModal: () => void;
  closeNewProjectModal: () => void;
  showExportModal: boolean;
  openExportModal: () => void;
  closeExportModal: () => void;
  showAudioSettingsModal: boolean;
  openAudioSettingsModal: () => void;
  closeAudioSettingsModal: () => void;
  showAboutModal: boolean;
  openAboutModal: () => void;
  closeAboutModal: () => void;
  // Additional Modals
  showSaveAsModal: boolean;
  openSaveAsModal: () => void;
  closeSaveAsModal: () => void;
  showOpenProjectModal: boolean;
  openOpenProjectModal: () => void;
  closeOpenProjectModal: () => void;
  showMidiSettingsModal: boolean;
  openMidiSettingsModal: () => void;
  closeMidiSettingsModal: () => void;
  showMixerOptionsModal: boolean;
  openMixerOptionsModal: () => void;
  closeMixerOptionsModal: () => void;
  showPreferencesModal: boolean;
  openPreferencesModal: () => void;
  closePreferencesModal: () => void;
  showShortcutsModal: boolean;
  openShortcutsModal: () => void;
  closeShortcutsModal: () => void;
  // Export
  exportAudio: (format: string, quality: string) => Promise<void>;
  // Project Import/Export
  exportProjectAsFile: () => void;
  importProjectFromFile: () => Promise<void>;
  // Bus/Routing functions
  buses: Bus[];
  createBus: (name: string) => void;
  deleteBus: (busId: string) => void;
  addTrackToBus: (trackId: string, busId: string) => void;
  removeTrackFromBus: (trackId: string, busId: string) => void;
  createSidechain: (sourceTrackId: string, targetTrackId: string) => void;
  // Plugin functions
  loadPlugin: (trackId: string, pluginName: string) => void;
  unloadPlugin: (trackId: string, pluginId: string) => void;
  loadedPlugins: Map<string, Plugin[]>;
  // MIDI functions
  midiDevices: MidiDevice[];
  createMIDIRoute: (sourceDeviceId: string, targetTrackId: string) => void;
  deleteMIDIRoute: (routeId: string) => void;
  getMIDIRoutesForTrack: (trackId: string) => MidiRoute[];
  // Codette AI Integration (Phase 1)
  codetteConnected: boolean;
  codetteLoading: boolean;
  codetteSuggestions: CodetteSuggestion[];
  getSuggestionsForTrack: (
    trackId: string,
    context?: string
  ) => Promise<CodetteSuggestion[]>;
  applyCodetteSuggestion: (
    trackId: string,
    suggestion: CodetteSuggestion
  ) => Promise<boolean>;
  analyzeTrackWithCodette: (trackId: string) => Promise<any>;
  syncDAWStateToCodette: () => Promise<boolean>;
  // Codette Transport Control (Phase 3)
  codetteTransportPlay: () => Promise<any>;
  codetteTransportStop: () => Promise<any>;
  codetteTransportSeek: (timeSeconds: number) => Promise<any>;
  codetteSetTempo: (bpm: number) => Promise<any>;
  codetteSetLoop: (
    enabled: boolean,
    startTime?: number,
    endTime?: number
  ) => Promise<any>;
  // WebSocket Status (Phase 4)
  getWebSocketStatus: () => { connected: boolean; reconnectAttempts: number };
  getCodetteBridgeStatus: () => {
    connected: boolean;
    reconnectCount: number;
    isReconnecting: boolean;
  };
  // Clipboard Operations
  clipboardData: { type: 'track' | 'clip' | null; data: any };
  cutTrack: (trackId: string) => void;
  copyTrack: (trackId: string) => void;
  pasteTrack: () => void;
  selectAllTracks: () => void;
  deselectAllTracks: () => void;
  selectedTracks: Set<string>;
  // Utility
  cpuUsageDetailed: Record<string, number>;

  // Effect Chain Management (Phase 9)
  effectChainsByTrack: Map<string, TrackEffectChain>;
  getTrackEffects: (trackId: string) => EffectInstanceState[];
  addEffectToTrack: (trackId: string, effectType: string) => EffectInstanceState;
  removeEffectFromTrack: (trackId: string, effectId: string) => boolean;
  updateEffectParameter: (trackId: string, effectId: string, paramName: string, value: unknown) => boolean;
  enableDisableEffect: (trackId: string, effectId: string, enabled: boolean) => boolean;
  setEffectWetDry: (trackId: string, effectId: string, wetDry: number) => boolean;
  getEffectChainForTrack: (trackId: string) => TrackEffectChain | undefined;
  processTrackEffects: (trackId: string, audio: Float32Array, sampleRate: number) => Promise<Float32Array>;
  hasActiveEffects: (trackId: string) => boolean;
}

const DAWContext = createContext<DAWContextType | undefined>(undefined);

export function DAWProvider({ children }: { children: React.ReactNode }) {
  const [currentProject, setCurrentProject] = useState<Project | null>(null);
  const [tracks, setTracks] = useState<Track[]>([]);
  const [selectedTrack, setSelectedTrack] = useState<Track | null>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [logicCoreMode, setLogicCoreMode] = useState<LogicCoreMode>("ON");
  const [deletedTracks, setDeletedTracks] = useState<Track[]>([]); // Trash
  const [undoHistory, setUndoHistory] = useState<Track[][]>([]); // Undo stack
  const [redoHistory, setRedoHistory] = useState<Track[][]>([]); // Redo stack
  const [voiceControlActive, setVoiceControlActive] = useState(false);
  const [isUploadingFile, setIsUploadingFile] = useState(false);
  const [uploadError, setUploadError] = useState<string | null>(null);
  // Clipboard State
  const [clipboardData, setClipboardData] = useState<{ type: 'track' | 'clip' | null; data: any }>({ type: null, data: null });
  const [selectedTracks, setSelectedTracks] = useState<Set<string>>(new Set());
  // Codette AI Integration (Phase 1)
  const [codetteConnected, setCodetteConnected] = useState(false);
  const [codetteLoading, setCodetteLoading] = useState(false);
  const [codetteSuggestions, setCodetteSuggestions] = useState<
    CodetteSuggestion[]
  >([]);
  
  // Recording state
  const [recordingTrackId, setRecordingTrackId] = useState<string | null>(null);
  const [recordingStartTime, setRecordingStartTime] = useState(0);
  const [recordingTakeCount, setRecordingTakeCount] = useState(0);
  const [recordingMode, setRecordingModeState] = useState<'audio' | 'midi' | 'overdub'>('audio');
  const [punchInEnabled, setPunchInEnabled] = useState(false);
  const [punchInTime, setPunchInTime] = useState(0);
  const [punchOutTime, setPunchOutTime] = useState(30);
  const [recordingBlob, setRecordingBlob] = useState<Blob | null>(null);
  const [recordingError, setRecordingError] = useState<string | null>(null);
  
  // Initialize CodetteBridge with error handling using useMemo
  const codetteRef = useRef<any>(null);
  
  useMemo(() => {
    try {
      const bridgeInstance = getCodetteBridge();
      codetteRef.current = bridgeInstance;
    } catch (err) {
      console.error("[DAWContext] Failed to initialize CodetteBridge:", err);
      codetteRef.current = null;
    }
  }, []);

  // Initialize action system (REAPER-like command palette)
  useEffect(() => {
    // This effect body will be filled once the context is created below
  }, []);
  
  // Phase 3: New state
  const [markers, setMarkers] = useState<Marker[]>([]);
  const [loopRegion, setLoopRegion] = useState<LoopRegion>({
    enabled: false,
    startTime: 0,
    endTime: 0,
  });
  const [metronomeSettings, setMetronomeSettings] = useState<MetronomeSettings>(
    {
      enabled: false,
      volume: 0.3,
      beatSound: "click",
      accentFirst: true,
    }
  );
  // Modal State
  const [showNewProjectModal, setShowNewProjectModal] = useState(false);
  const [showExportModal, setShowExportModal] = useState(false);
  const [showAudioSettingsModal, setShowAudioSettingsModal] = useState(false);
  const [showAboutModal, setShowAboutModal] = useState(false);
  const [showSaveAsModal, setShowSaveAsModal] = useState(false);
  const [showOpenProjectModal, setShowOpenProjectModal] = useState(false);
  const [showMidiSettingsModal, setShowMidiSettingsModal] = useState(false);
  const [showMixerOptionsModal, setShowMixerOptionsModal] = useState(false);
  const [showPreferencesModal, setShowPreferencesModal] = useState(false);
  const [showShortcutsModal, setShowShortcutsModal] = useState(false);
  // Bus/Routing State
  const [buses, setBuses] = useState<Bus[]>([]);
  // Plugin State
  const [loadedPlugins] = useState<Map<string, Plugin[]>>(new Map());
  // MIDI State
  const [midiDevices] = useState<MidiDevice[]>([]);
  const [midiRoutes, setMidiRoutes] = useState<MidiRoute[]>([]);

  // Effect Chain State (Phase 9)
  const effectChainManagerRef = useRef(getEffectChainManager());
  const trackEffectChainsRef = useRef<Map<string, any>>(new Map()); // Map<trackId, useEffectChain return>
  const [, setEffectChainVersion] = useState(0); // Force re-render on effect changes
  
  // Audio I/O State - Real device management
  const [selectedInputDeviceId, setSelectedInputDeviceId] = useState<string | null>(null);
  const [selectedOutputDeviceId, setSelectedOutputDeviceId] = useState<string | null>(null);
  const [audioDeviceError, setAudioDeviceError] = useState<string | null>(null);
  const [audioContextState, setAudioContextState] = useState<AudioContextState>('running');
  
  // Audio I/O State (legacy - for interface compatibility)
  const inputLevel = 0;
  const latencyMs = 5;
  const bufferUnderruns = 0;
  const bufferOverruns = 0;
  const isAudioIOActive = audioContextState === 'running';
  const audioIOError = audioDeviceError;
  const selectedInputDevice = selectedInputDeviceId ? { label: selectedInputDeviceId } : null;
  // CPU usage detailed
  const [cpuUsageDetailedState] = useState<Record<string, number>>({
    audio: 2,
    ui: 3,
    effects: 4,
    metering: 1,
    other: 2,
  });
  const zoom = 1;
  const cpuUsage = 12;
  const audioEngineRef = useRef(getAudioEngine());

  // Initialize project from storage on mount
  useEffect(() => {
    const savedProject = loadProjectFromStorage();
    if (savedProject) {
      setCurrentProject(savedProject);
      console.log("[DAWContext] Project restored from localStorage");
    }
  }, []); // Run only once on mount

  // Auto-save project whenever it changes
  useEffect(() => {
    if (!currentProject) return;

    const cleanup = createAutoSaveInterval(currentProject, (success) => {
      if (success) {
        console.debug("[DAWContext] Project auto-saved");
      }
    });

    return cleanup;
  }, [currentProject]);

  useEffect(() => {
    if (currentProject) {
      // Ensure master track exists
      const hasMasterTrack = currentProject.tracks?.some(
        (t) => t.type === "master"
      );
      let tracksToSet = currentProject.tracks || [];

      if (!hasMasterTrack) {
        const masterTrack: Track = {
          id: "master-main",
          name: "Master",
          type: "master",
          color: "#6366f1",
          muted: false,
          soloed: false,
          armed: false,
          inputGain: 0,
          volume: 0,
          pan: 0,
          stereoWidth: 100,
          phaseFlip: false,
          inserts: [],
          sends: [],
          routing: "Master",
          automationMode: "off",
        };
        tracksToSet = [...tracksToSet, masterTrack];
      }

      setTracks(tracksToSet);
    }
  }, [currentProject]);

  // Initialize Codette connection (Phase 1 & Phase 4: WebSocket)
  useEffect(() => {
    const bridge = codetteRef.current;
    
    if (!bridge) {
      console.warn("[DAWContext] CodetteBridge not initialized");
      return;
    }

    const handleConnected = () => setCodetteConnected(true);
    const handleDisconnected = () => setCodetteConnected(false);

    // WebSocket event handlers (Phase 4)
    const handleTransportChanged = (transportState: any) => {
      console.debug("[DAWContext] Received transport update from WebSocket:", transportState);
      // Note: seek() will be defined later in the component, so we can't call it here
      // The WebSocket sync is primarily for monitoring, not for triggering actions
    };

    const handleSuggestionReceived = (suggestion: any) => {
      console.debug("[DAWContext] Received suggestion from WebSocket:", suggestion);
      setCodetteSuggestions((prev) => [suggestion, ...prev].slice(0, 5)); // Keep latest 5
    };

    const handleAnalysisComplete = (analysis: any) => {
      console.debug("[DAWContext] Analysis complete from WebSocket:", analysis);
      // Analysis data received, UI handles this via component re-renders
    };

    const handleWsConnected = (connected: boolean) => {
      console.debug("[DAWContext] WebSocket status changed:", connected);
      // Could trigger additional sync when WS connects
    };

    bridge.on("connected", handleConnected);
    bridge.on("disconnected", handleDisconnected);
    bridge.on("transport_changed", handleTransportChanged);
    bridge.on("suggestion_received", handleSuggestionReceived);
    bridge.on("analysis_complete", handleAnalysisComplete);
    bridge.on("ws_connected", handleWsConnected);

    // Initial health check
    bridge.healthCheck().then((connected: boolean) => {
      setCodetteConnected(connected);
    });

    return () => {
      bridge.off("connected", handleConnected);
      bridge.off("disconnected", handleDisconnected);
      bridge.off("transport_changed", handleTransportChanged);
      bridge.off("suggestion_received", handleSuggestionReceived);
      bridge.off("analysis_complete", handleAnalysisComplete);
      bridge.off("ws_connected", handleWsConnected);
    };
  }, []);

  // Sync DAW state to Codette periodically (Phase 1)
  useEffect(() => {
    if (!codetteConnected || !isPlaying || !codetteRef.current) return;

    const syncInterval = setInterval(() => {
      const bridge = codetteRef.current;
      if (!bridge) return;
      bridge
        .syncState(tracks, currentTime, isPlaying, 120) // Default to 120 BPM for now
        .catch((err: unknown) => {
          console.debug("[DAWContext] Sync failed:", err);
        });
    }, 5000); // Sync every 5 seconds during playback

    return () => clearInterval(syncInterval);
  }, [codetteConnected, tracks, currentTime, isPlaying]);

  useEffect(() => {
    if (isPlaying) {
      const interval = setInterval(() => {
        setCurrentTime((prev) => prev + 0.1);
      }, 100);
      return () => clearInterval(interval);
    }
  }, [isPlaying]);

  // Sync track volume, pan, and effects during playback for real-time updates
  useEffect(() => {
    if (isPlaying) {
      tracks.forEach((track) => {
        // Use smooth sync methods for real-time parameter updates
        audioEngineRef.current.syncTrackVolume(track.id, track.volume);
        audioEngineRef.current.syncTrackPan(track.id, track.pan);
        audioEngineRef.current.setStereoWidth(
          track.id,
          track.stereoWidth || 100
        );
        audioEngineRef.current.setPhaseFlip(track.id, track.phaseFlip || false);
        // Ensure input gain (pre-fader) is synced as well
        if (typeof track.inputGain === "number") {
          audioEngineRef.current.setTrackInputGain(track.id, track.inputGain);
        }
      });
    }
  }, [tracks, isPlaying]);

  // Sync transport state to Codette (Phase 3)
  useEffect(() => {
    if (!codetteConnected) return;

    const syncTransportInterval = setInterval(async () => {
      const bridge = codetteRef.current;

      try {
        // Get current Codette transport state
        const transportState = await bridge.getTransportState();

        // If Codette's playback state differs from ours, sync it
        if (transportState.is_playing !== isPlaying) {
          if (transportState.is_playing && !isPlaying) {
            // Codette playing, React not - start playback
            console.debug(
              "[DAWContext] Transport sync: Starting playback from Codette"
            );
            // Call internal play logic
            const audioEngine = audioEngineRef.current;
            tracks.forEach((track) => {
              if (!track.muted && track.type !== "master") {
                audioEngine.playAudio(
                  track.id,
                  currentTime,
                  track.volume,
                  track.pan,
                  track.inserts
                );
              }
            });
            setIsPlaying(true);
          } else if (!transportState.is_playing && isPlaying) {
            // React playing, Codette not - stop playback
            console.debug(
              "[DAWContext] Transport sync: Stopping playback from Codette"
            );
            audioEngineRef.current.stopAllAudio();
            setIsPlaying(false);
          }
        }

        // Sync seek position if they differ significantly (>0.5 seconds)
        if (
          Math.abs(transportState.current_time - currentTime) > 0.5 &&
          transportState.current_time !== currentTime
        ) {
          console.debug(
            "[DAWContext] Transport sync: Seeking to",
            transportState.current_time
          );
          seek(transportState.current_time);
        }
      } catch (error) {
        console.debug("[DAWContext] Transport sync failed:", error);
      }
    }, 1000); // Check transport state every 1 second

    return () => clearInterval(syncTransportInterval);
  }, [codetteConnected, isPlaying, currentTime]);

  // Cleanup on unmount
  useEffect(() => {
    const engineRef = audioEngineRef.current;
    return () => {
      engineRef?.dispose();
    };
  }, []);

  // Branching function: Get sequential track number for a given type
  const getTrackNumberForType = (type: Track["type"]): number => {
    const tracksOfType = tracks.filter((t) => t.type === type);
    return tracksOfType.length + 1;
  };

  // Branching function: Get random color from palette
  const getRandomTrackColor = (): string => {
    const colors = [
      "#3b82f6",
      "#ef4444",
      "#10b981",
      "#f59e0b",
      "#8b5cf6",
      "#ec4899",
      "#14b8a6",
      "#6366f1",
    ];
    return colors[Math.floor(Math.random() * colors.length)];
  };

  // Branching function: Create audio track
  const createAudioTrack = (): Track => {
    const trackNum = getTrackNumberForType("audio");
    return {
      id: `track-${Date.now()}`,
      name: `Audio ${trackNum}`,
      type: "audio",
      color: getRandomTrackColor(),
      muted: false,
      soloed: false,
      armed: false,
      inputGain: 0,
      volume: 0,
      pan: 0,
      stereoWidth: 100,
      phaseFlip: false,
      inserts: [],
      sends: [],
      routing: "Master",
      automationMode: "off",
    } as Track;
  };

  // Branching function: Create instrument track
  const createInstrumentTrack = (): Track => {
    const trackNum = getTrackNumberForType("instrument");
    return {
      id: `track-${Date.now()}`,
      name: `Instrument ${trackNum}`,
      type: "instrument",
      color: getRandomTrackColor(),
      muted: false,
      soloed: false,
      armed: false,
      inputGain: 0,
      volume: 0,
      pan: 0,
      stereoWidth: 100,
      phaseFlip: false,
      inserts: [],
      sends: [],
      routing: "Master",
      automationMode: "off",
    } as Track;
  };

  // Branching function: Create MIDI track
  const createMidiTrack = (): Track => {
    const trackNum = getTrackNumberForType("midi");
    return {
      id: `track-${Date.now()}`,
      name: `MIDI ${trackNum}`,
      type: "midi",
      color: getRandomTrackColor(),
      muted: false,
      soloed: false,
      armed: false,
      inputGain: 0,
      volume: 0,
      pan: 0,
      stereoWidth: 100,
      phaseFlip: false,
      inserts: [],
      sends: [],
      routing: "Master",
      automationMode: "off",
    } as Track;
  };

  // Branching function: Create aux track
  const createAuxTrack = (): Track => {
    const trackNum = getTrackNumberForType("aux");
    return {
      id: `track-${Date.now()}`,
      name: `Aux ${trackNum}`,
      type: "aux",
      color: getRandomTrackColor(),
      muted: false,
      soloed: false,
      armed: false,
      inputGain: 0,
      volume: 0,
      pan: 0,
      stereoWidth: 100,
      phaseFlip: false,
      inserts: [],
      sends: [],
      routing: "Master",
      automationMode: "off",
    } as Track;
  };

  // Branching function: Create VCA track
  const createVcaTrack = (): Track => {
    const trackNum = getTrackNumberForType("vca");
    return {
      id: `track-${Date.now()}`,
      name: `VCA ${trackNum}`,
      type: "vca",
      color: getRandomTrackColor(),
      muted: false,
      soloed: false,
      armed: false,
      inputGain: 0,
      volume: 0,
      pan: 0,
      stereoWidth: 100,
      phaseFlip: false,
      inserts: [],
      sends: [],
      routing: "Master",
      automationMode: "off",
    } as Track;
  };

  // Main branching router: Add track based on type
  const addTrack = (type: Track["type"]) => {
    let newTrack: Track;

    switch (type) {
      case "audio":
        newTrack = createAudioTrack();
        break;
      case "instrument":
        newTrack = createInstrumentTrack();
        break;
      case "midi":
        newTrack = createMidiTrack();
        break;
      case "aux":
        newTrack = createAuxTrack();
        break;
      case "vca":
        newTrack = createVcaTrack();
        break;
      case "master":
        // Master track is managed separately, should not be added here
        console.warn("Master track should not be added via addTrack()");
        return;
      default:
        // Fallback to audio track
        newTrack = createAudioTrack();
    }

    setTracks((prev) => [...prev, newTrack]);
    // Auto-select the newly added track
    setSelectedTrack(newTrack);
  };

  const selectTrack = (trackId: string) => {
    const track = tracks.find((t) => t.id === trackId);
    setSelectedTrack(track || null);
  };

  const updateTrack = (trackId: string, updates: Partial<Track>) => {
    setTracks((prev) =>
      prev.map((t) => (t.id === trackId ? { ...t, ...updates } : t))
    );
  };

  const deleteTrack = (trackId: string) => {
    // SOFT DELETE: Move to trash, don't permanently remove
    const trackToDelete = tracks.find((t) => t.id === trackId);
    if (trackToDelete) {
      // Save to undo history
      setUndoHistory((prev) => [...prev, tracks]);
      setRedoHistory([]); // Clear redo when new action taken

      // Move to trash
      setTracks((prev) => prev.filter((t) => t.id !== trackId));
      setDeletedTracks((prev) => [
        ...prev,
        { ...trackToDelete, deleted_at: new Date().toISOString() },
      ]);

      // Deselect if selected
      if (selectedTrack?.id === trackId) {
        setSelectedTrack(null);
      }

      console.log(`Track "${trackToDelete.name}" moved to trash`);
    }
  };

  // Restore track from trash
  const restoreTrack = (trackId: string) => {
    const trackToRestore = deletedTracks.find((t) => t.id === trackId);
    if (trackToRestore) {
      // Save to undo history
      setUndoHistory((prev) => [...prev, tracks]);
      setRedoHistory([]);

      // Restore from trash (remove any deletion metadata)
      setTracks((prev) => [...prev, trackToRestore]);
      setDeletedTracks((prev) => prev.filter((t) => t.id !== trackId));

      console.log(`Track "${trackToRestore.name}" restored from trash`);
    }
  };

  // Permanently delete track (irreversible - use with caution)
  const permanentlyDeleteTrack = (trackId: string) => {
    setDeletedTracks((prev) => prev.filter((t) => t.id !== trackId));
    console.log(`Track permanently deleted`);
  };

  // Undo last action
  const undo = () => {
    if (undoHistory.length > 0) {
      const previousState = undoHistory[undoHistory.length - 1];
      setRedoHistory((prev) => [...prev, tracks]);
      setTracks(previousState);
      setUndoHistory((prev) => prev.slice(0, -1));
      setSelectedTrack(null);
      console.log("Undo performed");
    }
  };

  // Redo last undone action
  const redo = () => {
    if (redoHistory.length > 0) {
      const nextState = redoHistory[redoHistory.length - 1];
      setUndoHistory((prev) => [...prev, tracks]);
      setTracks(nextState);
      setRedoHistory((prev) => prev.slice(0, -1));
      setSelectedTrack(null);
      console.log("Redo performed");
    }
  };

  // Clipboard Operations
  const cutTrack = (trackId: string) => {
    const trackToCut = tracks.find((t) => t.id === trackId);
    if (trackToCut) {
      setClipboardData({ type: 'track', data: JSON.parse(JSON.stringify(trackToCut)) });
      deleteTrack(trackId);
      console.log(`Track "${trackToCut.name}" cut to clipboard`);
    }
  };

  const copyTrack = (trackId: string) => {
    const trackToCopy = tracks.find((t) => t.id === trackId);
    if (trackToCopy) {
      setClipboardData({ type: 'track', data: JSON.parse(JSON.stringify(trackToCopy)) });
      console.log(`Track "${trackToCopy.name}" copied to clipboard`);
    }
  };

  const pasteTrack = () => {
    if (clipboardData.type === 'track' && clipboardData.data) {
      const pastedTrack = {
        ...clipboardData.data,
        id: `track-${Date.now()}`,
        name: `${clipboardData.data.name} (Copy)`,
      };
      setTracks((prev) => [...prev, pastedTrack]);
      setSelectedTrack(pastedTrack);
      console.log(`Track "${pastedTrack.name}" pasted from clipboard`);
    }
  };

  const duplicateTrack = async (trackId: string): Promise<Track | null> => {
    const sourceTrack = tracks.find((t) => t.id === trackId);
    if (!sourceTrack) {
      console.warn(`[DAWContext] Cannot duplicate missing track ${trackId}`);
      return null;
    }

    const uniqueId = `track-${Date.now()}`;
    const clonePlugins = sourceTrack.inserts.map((plugin, index) => ({
      ...plugin,
      id: `${plugin.id || "plugin"}-${uniqueId}-${index}`,
      parameters: { ...plugin.parameters },
    }
    ));
    const cloneSends = sourceTrack.sends.map((send, index) => ({
      ...send,
      id: `${send.id || "send"}-${uniqueId}-${index}`,
    }
    ));

    const clonedTrack: Track = {
      ...sourceTrack,
      id: uniqueId,
      name: `${sourceTrack.name} Copy`,
      inserts: clonePlugins,
      sends: cloneSends,
      childTrackIds: sourceTrack.childTrackIds
        ? [...sourceTrack.childTrackIds]
        : undefined,
    };

    setUndoHistory((prev) => [...prev, tracks]);
    setRedoHistory([]);
    setTracks((prev) => [...prev, clonedTrack]);
    setSelectedTrack(clonedTrack);

    if (sourceTrack.type !== "master") {
      try {
        await audioEngineRef.current.duplicateTrackAudioBuffer(
          sourceTrack.id,
          clonedTrack.id
        );
      } catch (error) {
        console.warn("[DAWContext] Failed to duplicate audio buffer:", error);
      }
    }

    console.log(`Track "${sourceShotTrack.name}" duplicated as "${clonedTrack.name}"`);
    return clonedTrack;
  };

  const selectAllTracks = () => {
    const allTrackIds = new Set(tracks.map((t) => t.id));
    setSelectedTracks(allTrackIds);
    console.log(`Selected all ${tracks.length} tracks`);
  };

  const deselectAllTracks = () => {
    setSelectedTracks(new Set());
    console.log('Deselected all tracks');
  };

  // Set input gain (pre-fader) for a track both in state and audio engine
  const setTrackInputGain = (trackId: string, gainDb: number) => {
    setTracks((prev) =>
      prev.map((t) => (t.id === trackId ? { ...t, inputGain: gainDb } : t))
    );
    try {
      audioEngineRef.current.setTrackInputGain(trackId, gainDb);
    } catch (error: unknown) {
      // audio engine might not be initialized yet — that's fine
      console.debug("setTrackInputGain error:", error);
    }
  };

  // Add a plugin to a track's insert chain
  const addPluginToTrack = (trackId: string, plugin: Plugin) => {
    setTracks((prev) =>
      prev.map((t) =>
        t.id === trackId ? { ...t, inserts: [...t.inserts, plugin] } : t
      )
    );
    // Update selected track if it was modified
    if (selectedTrack?.id === trackId) {
      setSelectedTrack((prev) =>
        prev ? { ...prev, inserts: [...prev.inserts, plugin] } : null
      );
    }
    // Auto-restart playback if playing to apply new plugin
    if (isPlaying) {
      audioEngineRef.current.stopAllAudio();
      setTimeout(() => {
        tracks.forEach((track) => {
          if (
            !track.muted &&
            (track.type === "audio" || track.type === "instrument")
          ) {
            audioEngineRef.current.playAudio(
              track.id,
              currentTime,
              track.volume,
              track.pan,
              track.id === trackId ? [...track.inserts, plugin] : track.inserts
            );
          }
        });
      }, 50);
    }
  };

  // Remove a plugin from a track's insert chain
  const removePluginFromTrack = (trackId: string, pluginId: string) => {
    setTracks((prev) =>
      prev.map((t) =>
        t.id === trackId
          ? { ...t, inserts: t.inserts.filter((p) => p.id !== pluginId) }
          : t
      )
    );
    // Update selected track if it was modified
    if (selectedTrack?.id === trackId) {
      setSelectedTrack((prev) =>
        prev
          ? { ...prev, inserts: prev.inserts.filter((p) => p.id !== pluginId) }
          : null
      );
    }
    // Auto-restart playback if playing to apply plugin removal
    if (isPlaying) {
      audioEngineRef.current.stopAllAudio();
      setTimeout(() => {
        tracks.forEach((track) => {
          if (
            !track.muted &&
            (track.type === "audio" || track.type === "instrument")
          ) {
            const newInserts = track.id === trackId
              ? track.inserts.filter((p) => p.id !== pluginId)
              : track.inserts;
            audioEngineRef.current.playAudio(
              track.id,
              currentTime,
              track.volume,
              track.pan,
              newInserts
            );
          }
        });
      }, 50);
    }
  };

  // Toggle plugin enabled/disabled
  const togglePluginEnabled = (
    trackId: string,
    pluginId: string,
    enabled: boolean
  ) => {
    setTracks((prev) =>
      prev.map((t) =>
        t.id === trackId
          ? {
              ...t,
              inserts: t.inserts.map((p) =>
                p.id === pluginId ? { ...p, enabled } : p
              ),
            }
          : t
      )
    );
    // Update selected track if it was modified
    if (selectedTrack?.id === trackId) {
      setSelectedTrack((prev) =>
        prev
          ? {
              ...prev,
              inserts: prev.inserts.map((p) =>
                p.id === pluginId ? { ...p, enabled } : p
              ),
            }
          : null
      );
    }
    // Auto-restart playback if playing to apply plugin enable/disable change
    if (isPlaying) {
      audioEngineRef.current.stopAllAudio();
      setTimeout(() => {
        tracks.forEach((track) => {
          if (
            !track.muted &&
            (track.type === "audio" || track.type === "instrument")
          ) {
            const newInserts = track.id === trackId
              ? track.inserts.map((p) =>
                  p.id === pluginId ? { ...p, enabled } : p
                )
              : track.inserts;
            audioEngineRef.current.playAudio(
              track.id,
              currentTime,
              track.volume,
              track.pan,
              newInserts
            );
          }
        });
      }, 50);
    }
  };

  const togglePlay = () => {
    if (!isPlaying) {
      // Starting playback
      audioEngineRef.current
        .initialize()
        .then(() => {
          // Play all non-muted audio and instrument tracks from current time
          tracks.forEach((track) => {
            if (
              !track.muted &&
              (track.type === "audio" || track.type === "instrument")
            ) {
              // playAudio expects linear volume (0-1), convert from dB
              audioEngineRef.current.playAudio(
                track.id,
                currentTime,
                track.volume,
                track.pan,
                track.inserts
              );
            }
          });
          setIsPlaying(true);
        })
        .catch((err) => console.error("Audio init failed:", err));
    } else {
      // Pausing playback
      audioEngineRef.current.stopAllAudio();
      setIsPlaying(false);
    }
  };

  const toggleRecord = () => {
    if (!isRecording) {
      // Starting recording - initialize audio engine first
      audioEngineRef.current
        .initialize()
        .then(async () => {
          const success = await audioEngineRef.current.startRecording();
          if (success) {
            setIsRecording(true);
            // Start playback if not already playing
            if (!isPlaying) {
              togglePlay();
            }
          } else {
            console.error(
              "Failed to start recording - getUserMedia may have been denied"
            );
          }
        })
        .catch((err) => console.error("Audio init failed during record:", err));
    } else {
      // Stopping recording - capture the blob and create a track
      audioEngineRef.current
        .stopRecording()
        .then((blob) => {
          if (blob) {
            // Create a new audio track from the recording
            const recordedFile = new File(
              [blob],
              `Recording-${Date.now()}.webm`,
              { type: "audio/webm" }
            );
            uploadAudioFile(recordedFile);
            console.log("Recording saved and imported as new track");
          }
          setIsRecording(false);
        })
        .catch((err) => console.error("Error stopping recording:", err));
    }
  };

  const stop = () => {
    // Stop recording first if active
    if (isRecording) {
      audioEngineRef.current
        .stopRecording()
        .then((blob) => {
          if (blob) {
            // Auto-save recording as new track
            const recordedFile = new File(
              [blob],
              `Recording-${Date.now()}.webm`,
              { type: "audio/webm" }
            );
            uploadAudioFile(recordedFile);
          }
        })
        .catch((err) => console.error("Error stopping recording:", err));
      setIsRecording(false);
    }

    // Stop all playback
    audioEngineRef.current.stopAllAudio();
    setIsPlaying(false);

    // Reset timeline to beginning
    setCurrentTime(0);
  };

  const seek = (timeSeconds: number) => {
    setCurrentTime(timeSeconds);

    if (isPlaying) {
      // If playing, stop all audio and restart from new position
      audioEngineRef.current.stopAllAudio();

      // Resume playback from seek time
      tracks.forEach((track) => {
        if (
          !track.muted &&
          (track.type === "audio" || track.type === "instrument")
        ) {
          audioEngineRef.current.playAudio(
            track.id,
            timeSeconds,
            track.volume,
            track.pan,
            track.inserts
          );
        }
      });
    }
    // If not playing, just update currentTime - playback will start from this position when play is pressed
  };

  // Effect Chain Management Functions (Phase 9)
  const getTrackEffects = (trackId: string): EffectInstanceState[] => {
    const manager = effectChainManagerRef.current;
    return manager.getEffectsForTrack(trackId);
  };

  const addEffectToTrack = (
    trackId: string,
    effectType: string
  ): EffectInstanceState => {
    const manager = effectChainManagerRef.current;
    const effect = manager.addEffectToTrack(trackId, effectType);
    // Trigger re-render
    setEffectChainVersion((v) => v + 1);
    console.log(
      `[DAWContext] Added ${effectType} effect to track ${trackId}`
    );
    return effect;
  };

  const removeEffectFromTrack = (
    trackId: string,
    effectId: string
  ): boolean => {
    const manager = effectChainManagerRef.current;
    const success = manager.removeEffectFromTrack(trackId, effectId);
    if (success) {
      setEffectChainVersion((v) => v + 1);
      console.log(
        `[DAWContext] Removed effect ${effectId} from track ${trackId}`
      );
    }
    return success;
  };

  const updateEffectParameter = (
    trackId: string,
    effectId: string,
    paramName: string,
    value: unknown
  ): boolean => {
    const manager = effectChainManagerRef.current;
    const success = manager.updateEffectParameter(
      trackId,
      effectId,
      paramName,
      value
    );
    if (success) {
      setEffectChainVersion((v) => v + 1);
    }
    return success;
  };

  const enableDisableEffect = (
    trackId: string,
    effectId: string,
    enabled: boolean
  ): boolean => {
    const manager = effectChainManagerRef.current;
    const success = manager.toggleEffect(trackId, effectId, enabled);
    if (success) {
      setEffectChainVersion((v) => v + 1);
      console.log(
        `[DAWContext] Effect ${effectId} on track ${trackId} ${
          enabled ? "enabled" : "disabled"
        }`
      );
    }
    return success;
  };

  const setEffectWetDry = (
    trackId: string,
    effectId: string,
    wetDry: number
  ): boolean => {
    const manager = effectChainManagerRef.current;
    const success = manager.setWetDry(trackId, effectId, wetDry);
    if (success) {
      setEffectChainVersion((v) => v + 1);
    }
    return success;
  };

  const getEffectChainForTrack = (
    trackId: string
  ): TrackEffectChain | undefined => {
    const manager = effectChainManagerRef.current;
    return manager.getChainForTrack(trackId);
  };

  const processTrackEffects = async (
    trackId: string,
    audio: Float32Array,
    sampleRate: number
  ): Promise<Float32Array> => {
    const manager = effectChainManagerRef.current;
    const chain = manager.getChainForTrack(trackId);

    if (!chain || !manager.hasActiveEffects(trackId)) {
      return audio;
    }

    try {
      // Get or create effect chain hook for this track
      let chainHook = trackEffectChainsRef.current.get(trackId);

      if (!chainHook) {
        // This will be initialized when track effects are first accessed
        console.debug(
          `[DAWContext] Effect chain hook not initialized for track ${trackId}`
        );
        return audio;
      }

      // Process through effect chain
      const processed = await chainHook.processAudio(audio, sampleRate);
      manager.setProcessingState(trackId, false);
      return processed;
    } catch (error) {
      const err =
        error instanceof Error ? error : new Error("Unknown error");
      manager.setError(trackId, err);
      console.error(
        `[DAWContext] Error processing effects for track ${trackId}:`,
        error
      );
      return audio;
    }
  };

  const hasActiveEffects = (trackId: string): boolean => {
    const manager = effectChainManagerRef.current;
    return manager.hasActiveEffects(trackId);
  };

  // Initialize action system with DAW context
  useEffect(() => {
    setDAWContext(contextValue);
  }, [
    togglePlay,
    addTrack,
    deleteTrack,
    duplicateTrack,
    updateTrack,
    seek,
    selectedTrack,
    isPlaying,
    currentTime,
  ]);

  return (
    <DAWContext.Provider value={contextValue}>
      {children}
    </DAWContext.Provider>
  );
}

// eslint-disable-next-line react-refresh/only-export-components
export function useDAW() {
  const context = useContext(DAWContext);
  if (!context) {
    throw new Error("useDAW must be used within DAWProvider");
  }
  return context;
}
