import React, {
  createContext,
  useContext,
  useState,
  useEffect,
  useRef,
  useMemo,
} from "react";
import type {
  Track,
  Project,
  LogicCoreMode,
  Plugin,
  Marker,
  LoopRegion,
  MetronomeSettings,
  Bus,
  MidiDevice,
  MidiRoute,
  AudioContextState,
} from "@/types";
import { getAudioEngine } from "../lib/audioEngine";
import { getCodetteBridge, CodetteSuggestion } from "../lib/codetteBridge";
import { setDAWContext } from "../lib/actions/initializeActions";
import { supabase } from "../lib/supabase";
import {
  saveProjectToStorage,
  loadProjectFromStorage,
  clearProjectStorage,
  createAutoSaveInterval,
} from "../lib/projectStorage";
import {
  downloadProjectFile,
  importProjectFromFile,
  openFileDialog,
} from "../lib/projectImportExport";
import { useEffectChain } from "../hooks/useEffectChain";

interface DAWContextType {
  currentProject: Project | null;
  tracks: Track[];
  selectedTrack: Track | null;
  isPlaying: boolean;
  isRecording: boolean;
  currentTime: number;
  zoom: number;
  logicCoreMode: LogicCoreMode;
  voiceControlActive: boolean;
  cpuUsage: number;
  isUploadingFile: boolean;
  uploadError: string | null;
  deletedTracks: Track[]; // Trash
  canUndo: boolean;
  canRedo: boolean;
  markers: Marker[];
  loopRegion: LoopRegion;
  metronomeSettings: MetronomeSettings;
  inputLevel: number;
  latencyMs: number;
  bufferUnderruns: number;
  bufferOverruns: number;
  isAudioIOActive: boolean;
  audioIOError: string | null;
  selectedInputDevice: { label: string } | null;
  selectedInputDeviceId: string | null;
  selectedOutputDeviceId: string | null;
  selectInputDevice: (deviceId: string) => Promise<void>;
  selectOutputDevice: (deviceId: string) => Promise<void>;
  getAudioContextStatus: () => AudioContextState | string;
  setCurrentProject: (project: Project | null) => void;
  addTrack: (type: Track["type"]) => void;
  selectTrack: (trackId: string) => void;
  updateTrack: (trackId: string, updates: Partial<Track>) => void;
  deleteTrack: (trackId: string) => void; // Soft delete to trash
  duplicateTrack: (trackId: string) => Promise<Track | null>;
  restoreTrack: (trackId: string) => void; // Restore from trash
  permanentlyDeleteTrack: (trackId: string) => void; // Hard delete
  togglePlay: () => void;
  toggleRecord: () => void;
  stop: () => void;
  setLogicCoreMode: (mode: LogicCoreMode) => void;
  toggleVoiceControl: () => void;
  saveProject: () => Promise<void>;
  loadProject: (projectId: string) => Promise<void>;
  uploadAudioFile: (file: File) => Promise<boolean>;
  getWaveformData: (trackId: string) => number[];
  getAudioDuration: (trackId: string) => number;
  getAudioBufferData: (trackId: string) => Float32Array | null;
  getAudioLevels: () => Uint8Array | null;
  seek: (timeSeconds: number) => void;
  setTrackInputGain: (trackId: string, gainDb: number) => void;
  addPluginToTrack: (trackId: string, plugin: Plugin) => void;
  removePluginFromTrack: (trackId: string, pluginId: string) => void;
  togglePluginEnabled: (
    trackId: string,
    pluginId: string,
    enabled: boolean
  ) => void;
  undo: () => void;
  redo: () => void;
  // Phase 3: Markers
  addMarker: (time: number, name: string) => void;
  deleteMarker: (markerId: string) => void;
  updateMarker: (markerId: string, updates: Partial<Marker>) => void;
  // Phase 3: Looping
  setLoopRegion: (startTime: number, endTime: number) => void;
  toggleLoop: () => void;
  clearLoopRegion: () => void;
  // Phase 3: Metronome
  toggleMetronome: () => void;
  setMetronomeVolume: (volume: number) => void;
  setMetronomeBeatSound: (sound: MetronomeSettings["beatSound"]) => void;
  // Modal State
  showNewProjectModal: boolean;
  openNewProjectModal: () => void;
  closeNewProjectModal: () => void;
  showExportModal: boolean;
  openExportModal: () => void;
  closeExportModal: () => void;
  showAudioSettingsModal: boolean;
  openAudioSettingsModal: () => void;
  closeAudioSettingsModal: () => void;
  showAboutModal: boolean;
  openAboutModal: () => void;
  closeAboutModal: () => void;
  // Additional Modals
  showSaveAsModal: boolean;
  openSaveAsModal: () => void;
  closeSaveAsModal: () => void;
  showOpenProjectModal: boolean;
  openOpenProjectModal: () => void;
  closeOpenProjectModal: () => void;
  showMidiSettingsModal: boolean;
  openMidiSettingsModal: () => void;
  closeMidiSettingsModal: () => void;
  showMixerOptionsModal: boolean;
  openMixerOptionsModal: () => void;
  closeMixerOptionsModal: () => void;
  showPreferencesModal: boolean;
  openPreferencesModal: () => void;
  closePreferencesModal: () => void;
  showShortcutsModal: boolean;
  openShortcutsModal: () => void;
  closeShortcutsModal: () => void;
  // Export
  exportAudio: (format: string, quality: string) => Promise<void>;
  // Project Import/Export
  exportProjectAsFile: () => void;
  importProjectFromFile: () => Promise<void>;
  // Bus/Routing functions
  buses: Bus[];
  createBus: (name: string) => void;
  deleteBus: (busId: string) => void;
  addTrackToBus: (trackId: string, busId: string) => void;
  removeTrackFromBus: (trackId: string, busId: string) => void;
  createSidechain: (sourceTrackId: string, targetTrackId: string) => void;
  // Plugin functions
  loadPlugin: (trackId: string, pluginName: string) => void;
  unloadPlugin: (trackId: string, pluginId: string) => void;
  loadedPlugins: Map<string, Plugin[]>;

  // MIDI functions
  midiDevices: MidiDevice[];
  createMIDIRoute: (sourceDeviceId: string, targetTrackId: string) => void;
  deleteMIDIRoute: (routeId: string) => void;
  getMIDIRoutesForTrack: (trackId: string) => MidiRoute[];


  // Codette AI Integration (Phase 1)
  codetteConnected: boolean;
  codetteLoading: boolean;
  codetteSuggestions: CodetteSuggestion[];
  getSuggestionsForTrack: (
    trackId: string,
    context?: string
  ) => Promise<CodetteSuggestion[]>;
  applyCodetteSuggestion: (
    trackId: string,
    suggestion: CodetteSuggestion
  ) => Promise<boolean>;
  analyzeTrackWithCodette: (trackId: string) => Promise<any>;
  syncDAWStateToCodette: () => Promise<boolean>;
  // Codette Transport Control (Phase 3)
  codetteTransportPlay: () => Promise<any>;
  codetteTransportStop: () => Promise<any>;
  codetteTransportSeek: (timeSeconds: number) => Promise<any>;
  codetteSetTempo: (bpm: number) => Promise<any>;
  codetteSetLoop: (
    enabled: boolean,
    startTime?: number,
    endTime?: number
  ) => Promise<any>;
  // WebSocket Status (Phase 4)
  getWebSocketStatus: () => { connected: boolean; reconnectAttempts: number };
  getCodetteBridgeStatus: () => {
    connected: boolean;
    reconnectCount: number;
    isReconnecting: boolean;
  };
  // Clipboard Operations
  clipboardData: { type: 'track' | 'clip' | null; data: any };
  cutTrack: (trackId: string) => void;
  copyTrack: (trackId: string) => void;
  pasteTrack: () => void;
  selectAllTracks: () => void;
  deselectAllTracks: () => void;
  selectedTracks: Set<string>;
  // Utility
  cpuUsageDetailed: Record<string, number>;
}

const DAWContext = createContext<DAWContextType | undefined>(undefined);

export function DAWProvider({ children }: { children: React.ReactNode }) {
  const [currentProject, setCurrentProject] = useState<Project | null>(null);
  const [tracks, setTracks] = useState<Track[]>([]);
  const [selectedTrack, setSelectedTrack] = useState<Track | null>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [logicCoreMode, setLogicCoreMode] = useState<LogicCoreMode>("ON");
  const [deletedTracks, setDeletedTracks] = useState<Track[]>([]); // Trash
  const [undoHistory, setUndoHistory] = useState<Track[][]>([]); // Undo stack
  const [redoHistory, setRedoHistory] = useState<Track[][]>([]); // Redo stack
  const [voiceControlActive, setVoiceControlActive] = useState(false);
  const [isUploadingFile, setIsUploadingFile] = useState(false);
  const [uploadError, setUploadError] = useState<string | null>(null);
  // Clipboard State
  const [clipboardData, setClipboardData] = useState<{ type: 'track' | 'clip' | null; data: any }>({ type: null, data: null });
  const [selectedTracks, setSelectedTracks] = useState<Set<string>>(new Set());
  // Codette AI Integration (Phase 1)
  const [codetteConnected, setCodetteConnected] = useState(false);
  const [codetteLoading, setCodetteLoading] = useState(false);
  const [codetteSuggestions, setCodetteSuggestions] = useState<
    CodetteSuggestion[]
  >([]);

  // Recording state
  const [recordingTrackId, setRecordingTrackId] = useState<string | null>(null);
  const [recordingStartTime, setRecordingStartTime] = useState(0);
  const [recordingTakeCount, setRecordingTakeCount] = useState(0);
  const [recordingMode, setRecordingModeState] = useState<'audio' | 'midi' | 'overdub'>('audio');
  const [punchInEnabled, setPunchInEnabled] = useState(false);
  const [punchInTime, setPunchInTime] = useState(0);
  const [punchOutTime, setPunchOutTime] = useState(30);
  const [recordingBlob, setRecordingBlob] = useState<Blob | null>(null);
  const [recordingError, setRecordingError] = useState<string | null>(null);

  // Initialize CodetteBridge with error handling using useMemo
  const codetteRef = useRef<any>(null);

  useMemo(() => {
    try {
      const bridgeInstance = getCodetteBridge();
      codetteRef.current = bridgeInstance;
    } catch (err) {
      console.error("[DAWContext] Failed to initialize CodetteBridge:", err);
      codetteRef.current = null;
    }
  }, []);

  // Initialize action system (REAPER-like command palette)
  useEffect(() => {
    // This effect body will be filled once the context is created below
  }, []);

  // Phase 3: New state
  const [markers, setMarkers] = useState<Marker[]>([]);
  const [loopRegion, setLoopRegion] = useState<LoopRegion>({
    enabled: false,
    startTime: 0,
    endTime: 0,
  });
  const [metronomeSettings, setMetronomeSettings] = useState<MetronomeSettings>(
    {
      enabled: false,
      volume: 0.3,
      beatSound: "click",
      accentFirst: true,
    }
  );
  // Modal State
  const [showNewProjectModal, setShowNewProjectModal] = useState(false);
  const [showExportModal, setShowExportModal] = useState(false);
  const [showAudioSettingsModal, setShowAudioSettingsModal] = useState(false);
  const [showAboutModal, setShowAboutModal] = useState(false);
  const [showSaveAsModal, setShowSaveAsModal] = useState(false);
  const [showOpenProjectModal, setShowOpenProjectModal] = useState(false);
  const [showMidiSettingsModal, setShowMidiSettingsModal] = useState(false);
  const [showMixerOptionsModal, setShowMixerOptionsModal] = useState(false);
  const [showPreferencesModal, setShowPreferencesModal] = useState(false);
  const [showShortcutsModal, setShowShortcutsModal] = useState(false);
  // Bus/Routing State
  const [buses, setBuses] = useState<Bus[]>([]);
  // Plugin State
  const [loadedPlugins] = useState<Map<string, Plugin[]>>(new Map());
  // MIDI State
  const [midiDevices] = useState<MidiDevice[]>([]);
  const [midiRoutes, setMidiRoutes] = useState<MidiRoute[]>([]);

  // Audio I/O State - Real device management
  const [selectedInputDeviceId, setSelectedInputDeviceId] = useState<string | null>(null);
  const [selectedOutputDeviceId, setSelectedOutputDeviceId] = useState<string | null>(null);
  const [audioDeviceError, setAudioDeviceError] = useState<string | null>(null);
  const [audioContextState, setAudioContextState] = useState<AudioContextState>('running');
  
  // Audio I/O State (legacy - for interface compatibility)
  const inputLevel = 0;
  const latencyMs = 5;
  const bufferUnderruns = 0;
  const bufferOverruns = 0;
  const isAudioIOActive = audioContextState === 'running';
  const audioIOError = audioDeviceError;
  const selectedInputDevice = selectedInputDeviceId ? { label: selectedInputDeviceId } : null;
  // CPU usage detailed
  const [cpuUsageDetailedState] = useState<Record<string, number>>({
    audio: 2,
    ui: 3,
    effects: 4,
    metering: 1,
    other: 2,
  });
  const zoom = 1;
  const cpuUsage = 12;
  const audioEngineRef = useRef(getAudioEngine());

  // Initialize project from storage on mount
  useEffect(() => {
    const savedProject = loadProjectFromStorage();
    if (savedProject) {
      setCurrentProject(savedProject);
      console.log("[DAWContext] Project restored from localStorage");
    }
  }, []); // Run only once on mount

  // Auto-save project whenever it changes
  useEffect(() => {
    if (!currentProject) return;

    const cleanup = createAutoSaveInterval(currentProject, (success) => {
      if (success) {
        console.debug("[DAWContext] Project auto-saved");
      }
    });

    return cleanup;
  }, [currentProject]);

  useEffect(() => {
    if (currentProject) {
      // Ensure master track exists
      const hasMasterTrack = currentProject.tracks?.some(
        (t) => t.type === "master"
      );
      let tracksToSet = currentProject.tracks || [];

      if (!hasMasterTrack) {
        const masterTrack: Track = {
          id: "master-main",
          name: "Master",
          type: "master",
          color: "#6366f1",
          muted: false,
          soloed: false,
          armed: false,
          inputGain: 0,
          volume: 0,
          pan: 0,
          stereoWidth: 100,
          phaseFlip: false,
          inserts: [],
          sends: [],
          routing: "Master",
          automationMode: "off",
        };
        tracksToSet = [...tracksToSet, masterTrack];
      }

      setTracks(tracksToSet);
    }
  }, [currentProject]);

  // Initialize Codette connection (Phase 1 & Phase 4: WebSocket)
  useEffect(() => {
    const bridge = codetteRef.current;
    
    if (!bridge) {
      console.warn("[DAWContext] CodetteBridge not initialized");
      return;
    }

    const handleConnected = () => setCodetteConnected(true);
    const handleDisconnected = () => setCodetteConnected(false);

    // WebSocket event handlers (Phase 4)
    const handleTransportChanged = (transportState: any) => {
      console.debug("[DAWContext] Received transport update from WebSocket:", transportState);
      // Note: seek() will be defined later in the component, so we can't call it here
      // The WebSocket sync is primarily for monitoring, not for triggering actions
    };

    const handleSuggestionReceived = (suggestion: any) => {
      console.debug("[DAWContext] Received suggestion from WebSocket:", suggestion);
      setCodetteSuggestions((prev) => [suggestion, ...prev].slice(0, 5)); // Keep latest 5
    };

    const handleAnalysisComplete = (analysis: any) => {
      console.debug("[DAWContext] Analysis complete from WebSocket:", analysis);
      // Analysis data received, UI handles this via component re-renders
    };

    const handleWsConnected = (connected: boolean) => {
      console.debug("[DAWContext] WebSocket status changed:", connected);
      // Could trigger additional sync when WS connects
    };

    bridge.on("connected", handleConnected);
    bridge.on("disconnected", handleDisconnected);
    bridge.on("transport_changed", handleTransportChanged);
    bridge.on("suggestion_received", handleSuggestionReceived);
    bridge.on("analysis_complete", handleAnalysisComplete);
    bridge.on("ws_connected", handleWsConnected);

    // Initial health check
    bridge.healthCheck().then((connected: boolean) => {
      setCodetteConnected(connected);
    });

    return () => {
      bridge.off("connected", handleConnected);
      bridge.off("disconnected", handleDisconnected);
      bridge.off("transport_changed", handleTransportChanged);
      bridge.off("suggestion_received", handleSuggestionReceived);
      bridge.off("analysis_complete", handleAnalysisComplete);
      bridge.off("ws_connected", handleWsConnected);
    };
  }, []);

  // Sync DAW state to Codette periodically (Phase 1)
  useEffect(() => {
    if (!codetteConnected || !isPlaying || !codetteRef.current) return;

    const syncInterval = setInterval(() => {
      const bridge = codetteRef.current;
      if (!bridge) return;
      bridge
        .syncState(tracks, currentTime, isPlaying, 120) // Default to 120 BPM for now
        .catch((err: unknown) => {
          console.debug("[DAWContext] Sync failed:", err);
        });
    }, 5000); // Sync every 5 seconds during playback

    return () => clearInterval(syncInterval);
  }, [codetteConnected, tracks, currentTime, isPlaying]);

  useEffect(() => {
    if (isPlaying) {
      const interval = setInterval(() => {
        setCurrentTime((prev) => prev + 0.1);
      }, 100);
      return () => clearInterval(interval);
    }
  }, [isPlaying]);

  // Sync track volume, pan, and effects during playback for real-time updates
  useEffect(() => {
    if (isPlaying) {
      tracks.forEach((track) => {
        // Use smooth sync methods for real-time parameter updates
        audioEngineRef.current.syncTrackVolume(track.id, track.volume);
        audioEngineRef.current.syncTrackPan(track.id, track.pan);
        audioEngineRef.current.setStereoWidth(
          track.id,
          track.stereoWidth || 100
        );
        audioEngineRef.current.setPhaseFlip(track.id, track.phaseFlip || false);
        // Ensure input gain (pre-fader) is synced as well
        if (typeof track.inputGain === "number") {
          audioEngineRef.current.setTrackInputGain(track.id, track.inputGain);
        }
      });
    }
  }, [tracks, isPlaying]);

  // Sync transport state to Codette (Phase 3)
  useEffect(() => {
    if (!codetteConnected) return;

    const syncTransportInterval = setInterval(async () => {
      const bridge = codetteRef.current;

      try {
        // Get current Codette transport state
        const transportState = await bridge.getTransportState();

        // If Codette's playback state differs from ours, sync it
        if (transportState.is_playing !== isPlaying) {
          if (transportState.is_playing && !isPlaying) {
            // Codette playing, React not - start playback
            console.debug(
              "[DAWContext] Transport sync: Starting playback from Codette"
            );
            // Call internal play logic
            const audioEngine = audioEngineRef.current;
            tracks.forEach((track) => {
              if (!track.muted && track.type !== "master") {
                audioEngine.playAudio(
                  track.id,
                  currentTime,
                  track.volume,
                  track.pan,
                  track.inserts
                );
              }
            });
            setIsPlaying(true);
          } else if (!transportState.is_playing && isPlaying) {
            // React playing, Codette not - stop playback
            console.debug(
              "[DAWContext] Transport sync: Stopping playback from Codette"
            );
            audioEngineRef.current.stopAllAudio();
            setIsPlaying(false);
          }
        }

        // Sync seek position if they differ significantly (>0.5 seconds)
        if (
          Math.abs(transportState.current_time - currentTime) > 0.5 &&
          transportState.current_time !== currentTime
        ) {
          console.debug(
            "[DAWContext] Transport sync: Seeking to",
            transportState.current_time
          );
          seek(transportState.current_time);
        }
      } catch (error) {
        console.debug("[DAWContext] Transport sync failed:", error);
      }
    }, 1000); // Check transport state every 1 second

    return () => clearInterval(syncTransportInterval);
  }, [codetteConnected, isPlaying, currentTime]);

  // Cleanup on unmount
  useEffect(() => {
    const engineRef = audioEngineRef.current;
    return () => {
      engineRef?.dispose();
    };
  }, []);

  // Branching function: Get sequential track number for a given type
  const getTrackNumberForType = (type: Track["type"]): number => {
    const tracksOfType = tracks.filter((t) => t.type === type);
    return tracksOfType.length + 1;
  };

  // Branching function: Get random color from palette
  const getRandomTrackColor = (): string => {
    const colors = [
      "#3b82f6",
      "#ef4444",
      "#10b981",
      "#f59e0b",
      "#8b5cf6",
      "#ec4899",
      "#14b8a6",
      "#6366f1",
    ];
    return colors[Math.floor(Math.random() * colors.length)];
  };

  // Branching function: Create audio track
  const createAudioTrack = (): Track => {
    const trackNum = getTrackNumberForType("audio");
    return {
      id: `track-${Date.now()}`,
      name: `Audio ${trackNum}`,
      type: "audio",
      color: getRandomTrackColor(),
      muted: false,
      soloed: false,
      armed: false,
      inputGain: 0,
      volume: 0,
      pan: 0,
      stereoWidth: 100,
      phaseFlip: false,
      inserts: [],
      sends: [],
      routing: "Master",
      automationMode: "off",
    } as Track;
  };

  // Branching function: Create instrument track
  const createInstrumentTrack = (): Track => {
    const trackNum = getTrackNumberForType("instrument");
    return {
      id: `track-${Date.now()}`,
      name: `Instrument ${trackNum}`,
      type: "instrument",
      color: getRandomTrackColor(),
      muted: false,
      soloed: false,
      armed: false,
      inputGain: 0,
      volume: 0,
      pan: 0,
      stereoWidth: 100,
      phaseFlip: false,
      inserts: [],
      sends: [],
      routing: "Master",
      automationMode: "off",
    } as Track;
  };

  // Branching function: Create MIDI track
  const createMidiTrack = (): Track => {
    const trackNum = getTrackNumberForType("midi");
    return {
      id: `track-${Date.now()}`,
      name: `MIDI ${trackNum}`,
      type: "midi",
      color: getRandomTrackColor(),
      muted: false,
      soloed: false,
      armed: false,
      inputGain: 0,
      volume: 0,
      pan: 0,
      stereoWidth: 100,
      phaseFlip: false,
      inserts: [],
      sends: [],
      routing: "Master",
      automationMode: "off",
    } as Track;
  };

  // Branching function: Create aux track
  const createAuxTrack = (): Track => {
    const trackNum = getTrackNumberForType("aux");
    return {
      id: `track-${Date.now()}`,
      name: `Aux ${trackNum}`,
      type: "aux",
      color: getRandomTrackColor(),
      muted: false,
      soloed: false,
      armed: false,
      inputGain: 0,
      volume: 0,
      pan: 0,
      stereoWidth: 100,
      phaseFlip: false,
      inserts: [],
      sends: [],
      routing: "Master",
      automationMode: "off",
    } as Track;
  };

  // Branching function: Create VCA track
  const createVcaTrack = (): Track => {
    const trackNum = getTrackNumberForType("vca");
    return {
      id: `track-${Date.now()}`,
      name: `VCA ${trackNum}`,
      type: "vca",
      color: getRandomTrackColor(),
      muted: false,
      soloed: false,
      armed: false,
      inputGain: 0,
      volume: 0,
      pan: 0,
      stereoWidth: 100,
      phaseFlip: false,
      inserts: [],
      sends: [],
      routing: "Master",
      automationMode: "off",
    } as Track;
  };

  // Main branching router: Add track based on type
  const addTrack = (type: Track["type"]) => {
    let newTrack: Track;

    switch (type) {
      case "audio":
        newTrack = createAudioTrack();
        break;
      case "instrument":
        newTrack = createInstrumentTrack();
        break;
      case "midi":
        newTrack = createMidiTrack();
        break;
      case "aux":
        newTrack = createAuxTrack();
        break;
      case "vca":
        newTrack = createVcaTrack();
        break;
      case "master":
        // Master track is managed separately, should not be added here
        console.warn("Master track should not be added via addTrack()");
        return;
      default:
        // Fallback to audio track
        newTrack = createAudioTrack();
    }

    setTracks((prev) => [...prev, newTrack]);
    // Auto-select the newly added track
    setSelectedTrack(newTrack);
  };

  const selectTrack = (trackId: string) => {
    const track = tracks.find((t) => t.id === trackId);
    setSelectedTrack(track || null);
  };

  const updateTrack = (trackId: string, updates: Partial<Track>) => {
    setTracks((prev) =>
      prev.map((t) => (t.id === trackId ? { ...t, ...updates } : t))
    );
  };

  const deleteTrack = (trackId: string) => {
    // SOFT DELETE: Move to trash, don't permanently remove
    const trackToDelete = tracks.find((t) => t.id === trackId);
    if (trackToDelete) {
      // Save to undo history
      setUndoHistory((prev) => [...prev, tracks]);
      setRedoHistory([]); // Clear redo when new action taken

      // Move to trash
      setTracks((prev) => prev.filter((t) => t.id !== trackId));
      setDeletedTracks((prev) => [
        ...prev,
        { ...trackToDelete, deleted_at: new Date().toISOString() },
      ]);

      // Deselect if selected
      if (selectedTrack?.id === trackId) {
        setSelectedTrack(null);
      }

      console.log(`Track "${trackToDelete.name}" moved to trash`);
    }
  };

  // Restore track from trash
  const restoreTrack = (trackId: string) => {
    const trackToRestore = deletedTracks.find((t) => t.id === trackId);
    if (trackToRestore) {
      // Save to undo history
      setUndoHistory((prev) => [...prev, tracks]);
      setRedoHistory([]);

      // Restore from trash (remove any deletion metadata)
      setTracks((prev) => [...prev, trackToRestore]);
      setDeletedTracks((prev) => prev.filter((t) => t.id !== trackId));

      console.log(`Track "${trackToRestore.name}" restored from trash`);
    }
  };

  // Permanently delete track (irreversible - use with caution)
  const permanentlyDeleteTrack = (trackId: string) => {
    setDeletedTracks((prev) => prev.filter((t) => t.id !== trackId));
    console.log(`Track permanently deleted`);
  };

  // Undo last action
  const undo = () => {
    if (undoHistory.length > 0) {
      const previousState = undoHistory[undoHistory.length - 1];
      setRedoHistory((prev) => [...prev, tracks]);
      setTracks(previousState);
      setUndoHistory((prev) => prev.slice(0, -1));
      setSelectedTrack(null);
      console.log("Undo performed");
    }
  };

  // Redo last undone action
  const redo = () => {
    if (redoHistory.length > 0) {
      const nextState = redoHistory[redoHistory.length - 1];
      setUndoHistory((prev) => [...prev, tracks]);
      setTracks(nextState);
      setRedoHistory((prev) => prev.slice(0, -1));
      setSelectedTrack(null);
      console.log("Redo performed");
    }
  };

  // Phase 3: Markers
  const addMarker = (time: number, name: string) => {
    const newMarker: Marker = {
      id: `marker-${Date.now()}`,
      name,
      time,
    };
    setMarkers((prev) => [...prev, newMarker]);
  };

  const deleteMarker = (markerId: string) => {
    setMarkers((prev) => prev.filter((m) => m.id !== markerId));
  };

  const updateMarker = (markerId: string, updates: Partial<Marker>) => {
    setMarkers((prev) =>
      prev.map((m) => (m.id === markerId ? { ...m, ...updates } : m))
    );
  };

  // Phase 3: Looping
  const setLoopRegionFn = (startTime: number, endTime: number) => {
    setLoopRegion({ enabled: true, startTime, endTime });
  };

  const toggleLoop = () => {
    setLoopRegion((prev) => ({ ...prev, enabled: !prev.enabled }));
  };

  const clearLoopRegion = () => {
    setLoopRegion({ enabled: false, startTime: 0, endTime: 0 });
  };

  // Phase 3: Metronome
  const toggleMetronome = () => {
    setMetronomeSettings((prev) => ({ ...prev, enabled: !prev.enabled }));
  };

  const setMetronomeVolume = (volume: number) => {
    setMetronomeSettings((prev) => ({ ...prev, volume }));
  };

  const setMetronomeBeatSound = (sound: MetronomeSettings["beatSound"]) => {
    setMetronomeSettings((prev) => ({ ...prev, beatSound: sound }));
  };

  // Modal handlers
  const openNewProjectModal = () => setShowNewProjectModal(true);
  const closeNewProjectModal = () => setShowNewProjectModal(false);

  const openExportModal = () => setShowExportModal(true);
  const closeExportModal = () => setShowExportModal(false);

  const openAudioSettingsModal = () => setShowAudioSettingsModal(true);
  const closeAudioSettingsModal = () => setShowAudioSettingsModal(false);

  const openAboutModal = () => setShowAboutModal(true);
  const closeAboutModal = () => setShowAboutModal(false);

  const openSaveAsModal = () => setShowSaveAsModal(true);
  const closeSaveAsModal = () => setShowSaveAsModal(false);

  const openOpenProjectModal = () => setShowOpenProjectModal(true);
  const closeOpenProjectModal = () => setShowOpenProjectModal(false);

  const openMidiSettingsModal = () => setShowMidiSettingsModal(true);
  const closeMidiSettingsModal = () => setShowMidiSettingsModal(false);

  const openMixerOptionsModal = () => setShowMixerOptionsModal(true);
  const closeMixerOptionsModal = () => setShowMixerOptionsModal(false);

  const openPreferencesModal = () => setShowPreferencesModal(true);
  const closePreferencesModal = () => setShowPreferencesModal(false);

  const openShortcutsModal = () => setShowShortcutsModal(true);
  const closeShortcutsModal = () => setShowShortcutsModal(false);

  // Export functions
  const exportAudio = async (format: string, quality: string) => {
    if (!currentProject) return;

    // Implement audio export logic here
    console.log(`Exporting audio: ${format}, Quality: ${quality}`);
  };

  const exportProjectAsFile = () => {
    if (!currentProject) return;

    const projectData = JSON.stringify(currentProject, null, 2);
    const blob = new Blob([projectData], { type: "application/json" });
    const url = URL.createObjectURL(blob);

    const a = document.createElement("a");
    a.href = url;
    a.download = `${currentProject.name.replace(
      /\s+/g,
      "_"
    )}_project.json`;
    a.click();

    URL.revokeObjectURL(url);
  };

  const importProjectFromFileHandler = async () => {
    const fileHandle = await openFileDialog(["application/json"]);
    if (!fileHandle) return;

    const file = await fileHandle.getFile();
    const content = await file.text();

    try {
      const importedProject = JSON.parse(content) as Project;
      loadProject(importedProject.id);
      console.log("Project imported:", importedProject);
    } catch (error) {
      console.error("Error importing project:", error);
    }
  };

  // Bus/Routing functions
  const createBus = (name: string) => {
    setBuses((prev) => [
      ...prev,
      {
        id: `bus-${Date.now()}`,
        name,
        tracks: [],
      },
    ]);
  };

  const deleteBus = (busId: string) => {
    setBuses((prev) => prev.filter((b) => b.id !== busId));
  };

  const addTrackToBus = (trackId: string, busId: string) => {
    setBuses((prev) =>
      prev.map((b) =>
        b.id === busId ? { ...b, tracks: [...b.tracks, trackId] } : b
      )
    );
  };

  const removeTrackFromBus = (trackId: string, busId: string) => {
    setBuses((prev) =>
      prev.map((b) =>
        b.id === busId
          ? { ...b, tracks: b.tracks.filter((t) => t !== trackId) }
          : b
      )
    );
  };

  const createSidechain = (sourceTrackId: string, targetTrackId: string) => {
    // Implement sidechain creation logic here
    console.log(`Creating sidechain: ${sourceTrackId} -> ${targetTrackId}`);
  };

  // Plugin functions
  const loadPlugin = (trackId: string, pluginName: string) => {
    const track = tracks.find((t) => t.id === trackId);
    if (!track) return;

    // Simulate plugin loading
    const newPlugin: Plugin = {
      id: `plugin-${Date.now()}`,
      name: pluginName,
      type: "vst3",
      enabled: true,
      parameters: {},
    };

    setTracks((prev) =>
      prev.map((t) =>
        t.id === trackId ? { ...t, inserts: [...t.inserts, newPlugin] } : t
      )
    );
  };

  const unloadPlugin = (trackId: string, pluginId: string) => {
    setTracks((prev) =>
      prev.map((t) =>
        t.id === trackId
          ? { ...t, inserts: t.inserts.filter((p) => p.id !== pluginId) }
          : t
      )
    );
  };

  // MIDI functions
  const createMIDIRoute = (sourceDeviceId: string, targetTrackId: string) => {
    const newRoute = {
      id: `midi-route-${Date.now()}`,
      sourceDeviceId,
      targetTrackId,
    };

    setMidiRoutes((prev) => [...prev, newRoute]);
  };

  const deleteMIDIRoute = (routeId: string) => {
    setMidiRoutes((prev) => prev.filter((r) => r.id !== routeId));
  };

  // Audio I/O functions
  const selectInputDevice = async (deviceId: string) => {
    setSelectedInputDeviceId(deviceId);
    // Implement real audio input device switching here
  };

  const selectOutputDevice = async (deviceId: string) => {
    setSelectedOutputDeviceId(deviceId);
    // Implement real audio output device switching here
  };

  // CPU Usage (detailed view)
  // This could be expanded to provide real detailed CPU usage data
  const cpuUsageDetailed = cpuUsageDetailedState;

  // Create context value object
  const contextValue = {
        currentProject,
        tracks,
        selectedTrack,
        isPlaying,
        isRecording,
        currentTime,
        zoom,
        logicCoreMode,
        voiceControlActive,
        cpuUsage,
        isUploadingFile,
        uploadError,
        setCurrentProject: handleSetCurrentProject,
        addTrack,
        selectTrack,
        updateTrack,
        deleteTrack,
        duplicateTrack,
        restoreTrack,
        permanentlyDeleteTrack,
        togglePlay,
        toggleRecord,
        stop,
        setLogicCoreMode,
        toggleVoiceControl,
        saveProject,
        loadProject,
        uploadAudioFile,
        getWaveformData,
        getAudioDuration,
        getAudioBufferData,
        getAudioLevels,
        seek,
        setTrackInputGain,
        addPluginToTrack,
        removePluginFromTrack,
        togglePluginEnabled,
        undo,
        redo,
        canUndo: undoHistory.length > 0,
        canRedo: redoHistory.length > 0,
        deletedTracks,
        // Phase 3
        markers,
        loopRegion,
        metronomeSettings,
        addMarker,
        deleteMarker,
        updateMarker,
        setLoopRegion: setLoopRegionFn,
        toggleLoop,
        clearLoopRegion,
        toggleMetronome,
        setMetronomeVolume,
        setMetronomeBeatSound,
        // Modal state
        showNewProjectModal,
        openNewProjectModal,
        closeNewProjectModal,
        showExportModal,
        openExportModal,
        closeExportModal,
        showAudioSettingsModal,
        openAudioSettingsModal,
        closeAudioSettingsModal,
        showAboutModal,
        openAboutModal,
        closeAboutModal,
        // Additional modals
        showSaveAsModal,
        openSaveAsModal,
        closeSaveAsModal,
        showOpenProjectModal,
        openOpenProjectModal,
        closeOpenProjectModal,
        showMidiSettingsModal,
        openMidiSettingsModal,
        closeMidiSettingsModal,
        showMixerOptionsModal,
        openMixerOptionsModal,
        closeMixerOptionsModal,
        showPreferencesModal,
        openPreferencesModal,
        closePreferencesModal,
        showShortcutsModal,
        openShortcutsModal,
        closeShortcutsModal,
        // Export
        exportAudio,
        exportProjectAsFile,
        importProjectFromFile: importProjectFromFileHandler,
        // Bus/Routing
        buses,
        createBus,
        deleteBus,
        addTrackToBus,
        removeTrackFromBus,
        createSidechain,
        // Plugin management
        loadPlugin,
        unloadPlugin,
        loadedPlugins,
        // MIDI
        midiDevices,
        createMIDIRoute,
        deleteMIDIRoute,
        getMIDIRoutesForTrack,
        // Audio I/O
        inputLevel,
        latencyMs,
        bufferUnderruns,
        bufferOverruns,
        isAudioIOActive,
        audioIOError,
        selectedInputDevice,
        // Audio Device Selection
        selectInputDevice,
        selectOutputDevice,
        getAudioContextStatus,
        selectedInputDeviceId,
        selectedOutputDeviceId,
        // CPU Usage
        cpuUsageDetailed: cpuUsageDetailedState,
        // Codette AI Integration (Phase 1)
        codetteConnected,
        codetteLoading,
        codetteSuggestions,
        getSuggestionsForTrack,
        applyCodetteSuggestion,
        analyzeTrackWithCodette,
        syncDAWStateToCodette,
        codetteTransportPlay,
        codetteTransportStop,
        codetteTransportSeek,
        codetteSetTempo,
        codetteSetLoop,
        getWebSocketStatus,
        getCodetteBridgeStatus,
        // Clipboard Operations
        clipboardData,
        cutTrack,
        copyTrack,
        pasteTrack,
        selectAllTracks,
        deselectAllTracks,
        selectedTracks,
        // Recording state
        recordingTrackId: recordingTrackId,
        recordingStartTime: recordingStartTime,
        recordingTakeCount: recordingTakeCount,
        recordingMode: recordingMode,
        punchInEnabled: punchInEnabled,
        punchInTime: punchInTime,
        punchOutTime: punchOutTime,
        recordingBlob: recordingBlob,
        recordingError: recordingError,
  };

  // Initialize action system with DAW context
  useEffect(() => {
    setDAWContext(contextValue);
  }, [
    togglePlay,
    addTrack,
    deleteTrack,
    duplicateTrack,
    updateTrack,
    seek,
    selectedTrack,
    isPlaying,
    currentTime,
  ]);

  return (
    <DAWContext.Provider value={contextValue}>
      {children}
    </DAWContext.Provider>
  );
}

// eslint-disable-next-line react-refresh/only-export-components
export function useDAW() {
  const context = useContext(DAWContext);
  if (!context) {
    throw new Error("useDAW must be used within DAWProvider");
  }
  return context;
}
