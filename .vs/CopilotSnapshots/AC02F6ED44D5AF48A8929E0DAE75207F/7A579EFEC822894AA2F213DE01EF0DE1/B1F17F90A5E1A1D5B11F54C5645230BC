import { createContext, useContext, useRef, useState, useEffect, ReactNode } from "react";
import type {
  Track,
  Project,
  LogicCoreMode,
  Plugin,
  Marker,
  LoopRegion,
  MetronomeSettings,
  Bus,
  MidiDevice,
  MidiRoute,
  AudioContextState,
} from "../types";
import { CodetteSuggestion } from "../lib/codetteBridge";
import { supabase } from "../lib/supabase";
import { useEffectChainAPI, EffectChainContextAPI } from "../lib/effectChainContextAdapter";

// Create context (may be undefined before provider mounts)
const DAWContext = createContext<DAWContextType | undefined>(undefined);

interface DAWContextType {
  currentProject: Project | null;
  tracks: Track[];
  selectedTrack: Track | null;
  isPlaying: boolean;
  isRecording: boolean;
  currentTime: number;
  zoom: number;
  logicCoreMode: LogicCoreMode;
  voiceControlActive: boolean;
  cpuUsage: number;
  isUploadingFile: boolean;
  uploadError: string | null;
  deletedTracks: Track[]; // Trash
  canUndo: boolean;
  canRedo: boolean;
  markers: Marker[];
  loopRegion: LoopRegion | null;
  metronomeSettings: MetronomeSettings;
  inputLevel: number;
  latencyMs: number;
  bufferUnderruns: number;
  bufferOverruns: number;
  isAudioIOActive: boolean;
  audioIOError: string | null;
  selectedInputDevice: { label: string } | null;
  selectedInputDeviceId: string | null;
  selectedOutputDeviceId: string | null;
  selectInputDevice: (deviceId: string) => Promise<void>;
  selectOutputDevice: (deviceId: string) => Promise<void>
  getAudioContextStatus: () => AudioContextState | string;
  setCurrentProject: (project: Project | null) => void;
  addTrack: (type: Track["type"]) => void;
  selectTrack: (trackId: string) => void;
  updateTrack: (trackId: string, updates: Partial<Track>) => void;
  deleteTrack: (trackId: string) => void; // Soft delete to trash
  duplicateTrack: (trackId: string) => Promise<Track | null>;
  restoreTrack: (trackId: string) => void; // Restore from trash
  permanentlyDeleteTrack: (trackId: string) => void; // Hard delete
  togglePlay: () => void;
  toggleRecord: () => void;
  stop: () => void;
  setLogicCoreMode: (mode: LogicCoreMode) => void;
  toggleVoiceControl: () => void;
  saveProject: () => Promise<void>;
  loadProject: (projectId: string) => Promise<void>;
  uploadAudioFile: (file: File) => Promise<boolean>;
  getWaveformData: (trackId: string) => number[];
  getAudioDuration: (trackId: string) => number;
  getAudioBufferData: (trackId: string) => Float32Array | null;
  getAudioLevels: () => Uint8Array | null;
  seek: (timeSeconds: number) => void;
  setTrackInputGain: (trackId: string, gainDb: number) => void;
  addPluginToTrack: (trackId: string, plugin: Plugin) => void;
  removePluginFromTrack: (trackId: string, pluginId: string) => void;
  togglePluginEnabled: (
    trackId: string,
    pluginId: string,
    enabled: boolean
  ) => void;
  undo: () => void;
  redo: () => void;
  // Phase 3: Markers
  addMarker: (time: number, name: string) => void;
  deleteMarker: (markerId: string) => void;
  updateMarker: (markerId: string, updates: Partial<Marker>) => void;
  // Phase 3: Looping
  setLoopRegion: (startTime: number, endTime: number) => void;
  toggleLoop: () => void;
  clearLoopRegion: () => void;
  // Phase 3: Metronome
  toggleMetronome: () => void;
  setMetronomeVolume: (volume: number) => void;
  setMetronomeBeatSound: (sound: MetronomeSettings["beatSound"]) => void;
  // Modal State
  showNewProjectModal: boolean;
  openNewProjectModal: () => void;
  closeNewProjectModal: () => void;
  showExportModal: boolean;
  openExportModal: () => void;
  closeExportModal: () => void;
  showAudioSettingsModal: boolean;
  openAudioSettingsModal: () => void;
  closeAudioSettingsModal: () => void;
  showAboutModal: boolean;
  openAboutModal: () => void;
  closeAboutModal: () => void;
  // Additional Modals
  showSaveAsModal: boolean;
  openSaveAsModal: () => void;
  closeSaveAsModal: () => void;
  showOpenProjectModal: boolean;
  openOpenProjectModal: () => void;
  closeOpenProjectModal: () => void;
  showMidiSettingsModal: boolean;
  openMidiSettingsModal: () => void;
  closeMidiSettingsModal: () => void;
  showMixerOptionsModal: boolean;
  openMixerOptionsModal: () => void;
  closeMixerOptionsModal: () => void;
  showPreferencesModal: boolean;
  openPreferencesModal: () => void;
  closePreferencesModal: () => void;
  showShortcutsModal: boolean;
  openShortcutsModal: () => void;
  closeShortcutsModal: () => void;
  // Export
  exportAudio: (format: string, quality: string) => Promise<void>;
  // Project Import/Export
  exportProjectAsFile: () => void;
  importProjectFromFile: () => Promise<void>;
  // Bus/Routing functions
  buses: Bus[];
  createBus: (name: string) => void;
  deleteBus: (busId: string) => void;
  addTrackToBus: (trackId: string, busId: string) => void;
  removeTrackFromBus: (trackId: string, busId: string) => void;
  createSidechain: (sourceTrackId: string, targetTrackId: string) => void;
  // Plugin functions
  loadPlugin: (trackId: string, pluginName: string) => void;
  unloadPlugin: (trackId: string, pluginId: string) => void;
  loadedPlugins: Map<string, Plugin[]>;
  // MIDI functions
  midiDevices: MidiDevice[];
  createMIDIRoute: (sourceDeviceId: string, targetTrackId: string) => void;
  deleteMIDIRoute: (routeId: string) => void;
  getMIDIRoutesForTrack: (trackId: string) => MidiRoute[];
  // Codette AI Integration (Phase 1)
  codetteConnected: boolean;
  codetteLoading: boolean;
  codetteSuggestions: CodetteSuggestion[];
  getSuggestionsForTrack: (
    trackId: string,
    context?: string
  ) => Promise<CodetteSuggestion[]>;
  applyCodetteSuggestion: (
    trackId: string,
    suggestion: CodetteSuggestion
  ) => Promise<boolean>;
  analyzeTrackWithCodette: (trackId: string) => Promise<any>;
  syncDAWStateToCodette: () => Promise<boolean>;
  // Codette Transport Control (Phase 3)
  codetteTransportPlay: () => Promise<any>;
  codetteTransportStop: () => Promise<any>;
  codetteTransportSeek: (timeSeconds: number) => Promise<any>;
  codetteSetTempo: (bpm: number) => Promise<any>;
  codetteSetLoop: (
    enabled: boolean,
    startTime?: number,
    endTime?: number
  ) => Promise<any>;
  // WebSocket Status (Phase 4)
  getWebSocketStatus: () => { connected: boolean; reconnectAttempts: number };
  getCodetteBridgeStatus: () => {
    connected: boolean;
    reconnectCount: number;
    isReconnecting: boolean;
  };
  // Clipboard Operations
  clipboardData: { type: 'track' | 'clip' | null; data: any | null };
  cutTrack: (trackId: string) => void;
  copyTrack: (trackId: string) => void;
  pasteTrack: () => void;
  selectAllTracks: () => void;
  deselectAllTracks: () => void;
  selectedTracks: Set<string>;
  // Utility
  cpuUsageDetailed: Record<string, number>;

  // Recording state (NEW)
  recordingTrackId: null | string;
  recordingStartTime: number;
  recordingTakeCount: number;
  recordingMode: 'audio' | 'midi' | 'overdub';
  punchInEnabled: boolean;
  punchInTime: number;
  punchOutTime: number;
  recordingBlob: Blob | null;
  recordingError: string | null;
  
  // Recording methods (NEW)
  startRecording: (trackId: string) => Promise<boolean>;
  stopRecording: () => Promise<Blob | null>;
  pauseRecording: () => boolean;
  resumeRecording: () => boolean;
  setRecordingMode: (mode: 'audio' | 'midi' | 'overdub') => void;
  setPunchInOut: (punchIn: number, punchOut: number) => void;
  togglePunchIn: () => void;
  undoLastRecording: () => void;

  // Phase 9: Effect Chain Management (from EffectChainContextAPI)
  effectChainsByTrack: EffectChainContextAPI['effectChainsByTrack'];
  getTrackEffects: EffectChainContextAPI['getTrackEffects'];
  addEffectToTrack: EffectChainContextAPI['addEffectToTrack'];
  removeEffectFromTrack: EffectChainContextAPI['removeEffectFromTrack'];
  updateEffectParameter: EffectChainContextAPI['updateEffectParameter'];
  enableDisableEffect: EffectChainContextAPI['enableDisableEffect'];
  setEffectWetDry: EffectChainContextAPI['setEffectWetDry'];
  getEffectChainForTrack: EffectChainContextAPI['getEffectChainForTrack'];
  processTrackEffects: EffectChainContextAPI['processTrackEffects'];
  hasActiveEffects: EffectChainContextAPI['hasActiveEffects'];
}

// DAW Provider component
export function DAWProvider({ children }: { children: ReactNode }) {
  // State and context initialization
  const [currentProject, setCurrentProject] = useState<Project | null>(null);
  const [tracks, setTracks] = useState<Track[]>([]);
  const [selectedTrack, setSelectedTrack] = useState<Track | null>(null);
  const [isPlaying, setIsPlaying] = useState<boolean>(false);
  const [isRecording, setIsRecording] = useState<boolean>(false);
  const [currentTime, setCurrentTime] = useState<number>(0);
  const [zoom, _setZoom] = useState<number>(1);
  const [logicCoreMode, setLogicCoreMode] = useState<LogicCoreMode>("ON");
  const [voiceControlActive, setVoiceControlActive] = useState<boolean>(false);
  const [cpuUsage, _setCpuUsage] = useState<number>(0);
  const [isUploadingFile, setIsUploadingFile] = useState<boolean>(false);
  const [uploadError, setUploadError] = useState<string | null>(null);
  const [deletedTracks, _setDeletedTracks] = useState<Track[]>([]);
  const [canUndo, _setCanUndo] = useState<boolean>(false);
  const [canRedo, _setCanRedo] = useState<boolean>(false);
  const [markers, _setMarkers] = useState<Marker[]>([]);
  const [loopRegion, _setLoopRegion] = useState<LoopRegion | null>(null);
  const [metronomeSettings, _setMetronomeSettings] = useState<MetronomeSettings>({
    enabled: false,
    volume: 1,
    beatSound: "click",
    accentFirst: false,
  });

  // Audio I/O State - Real device management
  const [selectedInputDeviceId, _setSelectedInputDeviceId] = useState<string | null>(null);
  const [selectedOutputDeviceId, _setSelectedOutputDeviceId] = useState<string | null>(null);
  const [inputLevel, _setInputLevel] = useState<number>(0);
  const [latencyMs, _setLatencyMs] = useState<number>(0);
  const [bufferUnderruns, _setBufferUnderruns] = useState<number>(0);
  const [bufferOverruns, _setBufferOverruns] = useState<number>(0);
  const [isAudioIOActive, _setIsAudioIOActive] = useState<boolean>(false);
  const [audioIOError, _setAudioIOError] = useState<string | null>(null);

  // MIDI State
  const [midiDevices] = useState<MidiDevice[]>([]);
  
  // Phase 9: Effect Chain API
  const effectChainAPI = useEffectChainAPI();
  
  // Recording state (NEW)
  const [recordingTrackId, _setRecordingTrackId] = useState<string | null>(null);
  const [recordingStartTime, _setRecordingStartTime] = useState<number>(0);
  const [recordingTakeCount, setRecordingTakeCount] = useState<number>(0);
  const [recordingModeState, setRecordingModeState] = useState<'audio' | 'midi' | 'overdub'>('audio');
  const [punchInEnabled, _setPunchInEnabled] = useState<boolean>(false);
  const [punchInTime, _setPunchInTime] = useState<number>(0);
  const [punchOutTime, _setPunchOutTime] = useState<number>(0);
  const [recordingBlob, _setRecordingBlob] = useState<Blob | null>(null);
  const [recordingError, _setRecordingError] = useState<string | null>(null);

  // WebSocket Status (Phase 4)
  const [webSocketStatus, _setWebSocketStatus] = useState<{ connected: boolean; reconnectAttempts: number }>({
    connected: false,
    reconnectAttempts: 0,
  });

  // Simple playback timer
  const playTimerRef = useRef<number | null>(null);
  const lastTickRef = useRef<number | null>(null);

  useEffect(() => {
    if (isPlaying) {
      lastTickRef.current = performance.now();
      const tick = () => {
        const now = performance.now();
        const last = lastTickRef.current ?? now;
        const deltaSec = (now - last) / 1000;
        lastTickRef.current = now;
        setCurrentTime((prev) => prev + deltaSec);
        playTimerRef.current = requestAnimationFrame(tick);
      };
      playTimerRef.current = requestAnimationFrame(tick);
    } else if (playTimerRef.current) {
      cancelAnimationFrame(playTimerRef.current);
      playTimerRef.current = null;
      lastTickRef.current = null;
    }
    return () => {
      if (playTimerRef.current) {
        cancelAnimationFrame(playTimerRef.current);
        playTimerRef.current = null;
      }
    };
  }, [isPlaying]);

  // Demo waveform and duration cache (stable across renders)
  const waveformCacheRef = useRef<Map<string, number[]>>(new Map());
  const durationCacheRef = useRef<Map<string, number>>(new Map());

  const ensureDemoDataForTrack = (trackId: string) => {
    if (!waveformCacheRef.current.has(trackId)) {
      const length = 4096;
      const data = Array.from({ length }, (_, i) => {
        const t = (i / length) * Math.PI * 4;
        return Math.abs(Math.sin(t) * 0.6 + Math.sin(t * 2) * 0.3 + Math.sin(t * 3) * 0.1 + Math.random() * 0.05);
      });
      waveformCacheRef.current.set(trackId, data);
    }
    if (!durationCacheRef.current.has(trackId)) {
      durationCacheRef.current.set(trackId, 60); // default 60s
    }
  };

  const getAudioContextStatus = () => {
    return "running";
  };

  const togglePlay = () => {
    setIsPlaying((prev) => !prev);
  };

  const toggleRecord = () => {
    setIsRecording((prev) => !prev);
  };

  const stop = () => {
    setIsPlaying(false);
    setIsRecording(false);
    setCurrentTime(0);
  };

  const saveProject = async () => {
    if (!currentProject) return;
    setIsUploadingFile(true);
    try {
      await supabase
        .from("projects")
        .insert([{ ...currentProject, id: undefined }])
        .single();
      setCurrentProject(currentProject);
    } catch (error) {
      console.error("Error saving project:", error);
      setUploadError("Error saving project. Please try again.");
    } finally {
      setIsUploadingFile(false);
    }
  };

  const loadProject = async (projectId: string) => {
    setIsUploadingFile(true);
    try {
      const { data, error } = await supabase
        .from("projects")
        .select("*")
        .eq("id", projectId)
        .single();

      if (error) throw error;

      setCurrentProject(data);
    } catch (error) {
      console.error("Error loading project:", error);
      setUploadError("Error loading project. Please try again.");
    } finally {
      setIsUploadingFile(false);
    }
  };

  // Sync DAW state to Codette AI (Phase 1)
  const syncDAWStateToCodette = async () => {
    return true;
  };

  // Codette Transport Control (Phase 3)
  const codetteTransportPlay = async () => {};
  const codetteTransportStop = async () => {};
  const codetteTransportSeek = async (_timeSeconds: number) => {};
  const codetteSetTempo = async (_bpm: number) => {};
  const codetteSetLoop = async (
    _enabled: boolean,
    _startTime?: number,
    _endTime?: number
  ) => {};

  const cutTrack = (_trackId: string) => {};
  const copyTrack = (_trackId: string) => {};
  const pasteTrack = () => {};
  const selectAllTracks = () => {};
  const deselectAllTracks = () => {};

  const startRecording = async (_trackId: string) => {
    return true;
  };
  const stopRecording = async () => {
    return null;
  };
  const pauseRecording = () => {
    return true;
  };
  const resumeRecording = () => {
    return true;
  };
  const setRecordingMode = (mode: 'audio' | 'midi' | 'overdub') => {
    setRecordingModeState(mode);
  };
  const setPunchInOut = (_punchIn: number, _punchOut: number) => {};
  const togglePunchIn = () => {};
  const undoLastRecording = () => {
    console.log("Undo last recording action");
    setRecordingTakeCount((prev: number) => Math.max(0, prev - 1));
  };

  const toggleVoiceControl = () => setVoiceControlActive((prev) => !prev);
  const undo = () => { console.log("undo"); };
  const redo = () => { console.log("redo"); };

  const contextValue = {
    currentProject,
    tracks,
    selectedTrack,
    isPlaying,
    isRecording,
    currentTime,
    zoom,
    logicCoreMode,
    voiceControlActive,
    cpuUsage,
    isUploadingFile,
    uploadError,
    deletedTracks,
    canUndo,
    canRedo,
    markers,
    loopRegion,
    metronomeSettings,
    inputLevel,
    latencyMs,
    bufferUnderruns,
    bufferOverruns,
    isAudioIOActive,
    audioIOError,
    selectedInputDevice: null,
    selectedInputDeviceId,
    selectedOutputDeviceId,
    selectInputDevice: async (deviceId: string) => { _setSelectedInputDeviceId(deviceId); },
    selectOutputDevice: async (deviceId: string) => { _setSelectedOutputDeviceId(deviceId); },
    getAudioContextStatus,
    setCurrentProject,
    addTrack: (type: Track["type"]) => {
      const t: Track = {
        id: `track-${Date.now()}`,
        name: `${type} ${tracks.length + 1}`,
        type,
        color: '#888',
        muted: false,
        soloed: false,
        armed: false,
        inputGain: 0,
        volume: 0,
        pan: 0,
        stereoWidth: 100,
        phaseFlip: false,
        inserts: [],
        sends: [],
        routing: '',
      };
      setTracks((prev) => [...prev, t]);
      // Prepare demo data for new track (stable reference)
      ensureDemoDataForTrack(t.id);
    },
    selectTrack: (trackId: string) => {
      const t = tracks.find((tr) => tr.id === trackId) || null;
      setSelectedTrack(t);
      if (t) ensureDemoDataForTrack(t.id);
    },
    updateTrack: (trackId: string, updates: Partial<Track>) => {
      setTracks((prev) => prev.map((t) => (t.id === trackId ? { ...t, ...updates } : t)));
    },
    deleteTrack: (trackId: string) => {
      setTracks((prev) => prev.filter((t) => t.id !== trackId));
      const del = tracks.find((t) => t.id === trackId);
      if (del) _setDeletedTracks((prev) => [...prev, del]);
    },
    duplicateTrack: async (trackId: string) => {
      const source = tracks.find((t) => t.id === trackId);
      if (!source) return null;
      const copy: Track = { ...source, id: `track-${Date.now()}` };
      setTracks((prev) => [...prev, copy]);
      // copy cached data
      const wf = waveformCacheRef.current.get(source.id);
      if (wf) waveformCacheRef.current.set(copy.id, wf);
      const dur = durationCacheRef.current.get(source.id);
      if (dur) durationCacheRef.current.set(copy.id, dur);
      return copy;
    },
    restoreTrack: (trackId: string) => {
      _setDeletedTracks((prev) => {
        const idx = prev.findIndex((t) => t.id === trackId);
        if (idx === -1) return prev;
        const track = prev[idx];
        setTracks((tracksPrev) => [...tracksPrev, track]);
        const next = [...prev];
        next.splice(idx, 1);
        return next;
      });
    },
    permanentlyDeleteTrack: async () => {},
    togglePlay,
    toggleRecord,
    stop,
    setLogicCoreMode,
    toggleVoiceControl,
    saveProject,
    loadProject,
    uploadAudioFile: async () => false,
    // Stable getters to avoid infinite re-render loops
    getWaveformData: (trackId: string) => {
      ensureDemoDataForTrack(trackId);
      return waveformCacheRef.current.get(trackId) as number[];
    },
    getAudioDuration: (trackId: string) => {
      ensureDemoDataForTrack(trackId);
      return durationCacheRef.current.get(trackId) as number;
    },
    getAudioBufferData: () => null,
    getAudioLevels: () => null,
    seek: (timeSeconds: number) => {
      setCurrentTime(Math.max(0, timeSeconds));
    },
    setTrackInputGain: () => {},
    addPluginToTrack: () => {},
    removePluginFromTrack: () => {},
    togglePluginEnabled: () => {},
    undo,
    redo,
    // Phase 3: Markers
    addMarker: (time: number, name: string) => {
      const marker: Marker = { id: `marker-${Date.now()}`, name, time, color: '#fff', locked: false };
      _setMarkers((prev) => [...prev, marker]);
    },
    deleteMarker: (markerId: string) => {
      _setMarkers((prev) => prev.filter((m) => m.id !== markerId));
    },
    updateMarker: (markerId: string, updates: Partial<Marker>) => {
      _setMarkers((prev) => prev.map((m) => (m.id === markerId ? { ...m, ...updates } : m)));
    },
    // Phase 3: Looping
    setLoopRegion: (startTime: number, endTime: number) => {
      _setLoopRegion({ enabled: true, startTime, endTime });
    },
    toggleLoop: () => {
      _setLoopRegion((prev) => (prev ? { ...prev, enabled: !prev.enabled } : { enabled: true, startTime: 0, endTime: 0 }));
    },
    clearLoopRegion: () => {
      _setLoopRegion(null);
    },
    // Phase 3: Metronome
    toggleMetronome: () => {},
    setMetronomeVolume: () => {},
    setMetronomeBeatSound: () => {},
    // Modal State
    showNewProjectModal: false,
    openNewProjectModal: () => {},
    closeNewProjectModal: () => {},
    showExportModal: false,
    openExportModal: () => {},
    closeExportModal: () => {},
    showAudioSettingsModal: false,
    openAudioSettingsModal: () => {},
    closeAudioSettingsModal: () => {},
    showAboutModal: false,
    openAboutModal: () => {},
    closeAboutModal: () => {},
    // Additional Modals
    showSaveAsModal: false,
    openSaveAsModal: () => {},
    closeSaveAsModal: () => {},
    showOpenProjectModal: false,
    openOpenProjectModal: () => {},
    closeOpenProjectModal: () => {},
    showMidiSettingsModal: false,
    openMidiSettingsModal: () => {},
    closeMidiSettingsModal: () => {},
    showMixerOptionsModal: false,
    openMixerOptionsModal: () => {},
    closeMixerOptionsModal: () => {},
    showPreferencesModal: false,
    openPreferencesModal: () => {},
    closePreferencesModal: () => {},
    showShortcutsModal: false,
    openShortcutsModal: () => {},
    closeShortcutsModal: () => {},
    // Export
    exportAudio: async () => {},
    // Project Import/Export
    exportProjectAsFile: () => {},
    importProjectFromFile: async () => {},
    // Bus/Routing functions
    buses: [],
    createBus: async () => {},
    deleteBus: async () => {},
    addTrackToBus: async () => {},
    removeTrackFromBus: async () => {},
    createSidechain: async () => {},
    // Plugin functions
    loadPlugin: () => {},
    unloadPlugin: () => {},
    loadedPlugins: new Map<string, Plugin[]>(),
    // MIDI functions
    midiDevices,
    createMIDIRoute: async () => {},
    deleteMIDIRoute: async () => {},
    getMIDIRoutesForTrack: () => [],
    // Codette AI Integration (Phase 1)
    codetteConnected: false,
    codetteLoading: false,
    codetteSuggestions: [] as CodetteSuggestion[],
    getSuggestionsForTrack: async () => [],
    applyCodetteSuggestion: async () => false,
    analyzeTrackWithCodette: async () => ({}),
    syncDAWStateToCodette,
    // Codette Transport Control (Phase 3)
    codetteTransportPlay,
    codetteTransportStop,
    codetteTransportSeek,
    codetteSetTempo,
    codetteSetLoop,
    // WebSocket Status (Phase 4)
    getWebSocketStatus: () => webSocketStatus,
    getCodetteBridgeStatus: () => ({
      connected: false,
      reconnectCount: 0,
      isReconnecting: false,
    }),
    // Clipboard Operations
    clipboardData: { type: null, data: null },
    cutTrack,
    copyTrack,
    pasteTrack,
    selectAllTracks,
    deselectAllTracks,
    selectedTracks: new Set<string>(),
    // Utility
    cpuUsageDetailed: {},

    // Recording state (NEW)
    recordingTrackId,
    recordingStartTime,
    recordingTakeCount,
    recordingMode: recordingModeState,
    punchInEnabled,
    punchInTime,
    punchOutTime,
    recordingBlob,
    recordingError,
    
    // Recording methods (NEW)
    startRecording,
    stopRecording,
    pauseRecording,
    resumeRecording,
    setRecordingMode,
    setPunchInOut,
    togglePunchIn,
    undoLastRecording,

    // Phase 9: Effect Chain Management (from EffectChainContextAPI)
    ...effectChainAPI,
  };

  return (
    <DAWContext.Provider value={contextValue}>
      {children}
    </DAWContext.Provider>
  );
}

// Hook that asserts presence of provider and returns a non-undefined context
export const useDAW = (): DAWContextType => {
  const ctx = useContext(DAWContext);
  if (!ctx) throw new Error("useDAW must be used within DAWProvider");
  return ctx;
};
