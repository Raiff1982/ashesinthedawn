#!/usr/bin/env python
"""
Codette AI Unified Server
Combined FastAPI server for CoreLogic Studio DAW integration
Includes both standard endpoints and production-optimized features
"""

import sys
import os
import json
import logging
import asyncio
import time
import traceback
import hashlib
import uuid
from pathlib import Path
from typing import Optional, Dict, Any, List
from datetime import datetime, timezone
from functools import lru_cache

# Load environment variables from .env file
try:
    from dotenv import load_dotenv
    env_file = Path(__file__).parent / '.env'
    if env_file.exists():
        load_dotenv(env_file)
except ImportError:
    pass  # dotenv not installed, fall back to environment variables

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# Try to import Supabase for music knowledge base
try:
    import supabase
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("[WARNING] Supabase not installed - install with: pip install supabase")

# Try to import Redis for persistent caching
try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    print("[INFO] Redis not installed - using in-memory cache (install with: pip install redis)")

# Try to import Codette Enhanced System
try:
    from codette_enhanced_responder import (
        get_enhanced_responder,
        UserRating,
        CodetteEnhancedResponder
    )
    ENHANCED_RESPONDER_AVAILABLE = True
    logger_setup = logging.getLogger(__name__)
    logger_setup.info("[✅] Codette Enhanced Responder imported successfully")
except ImportError as e:
    ENHANCED_RESPONDER_AVAILABLE = False
    logger_setup = logging.getLogger(__name__)
    logger_setup.warning(f"[⚠️] Codette Enhanced Responder not available: {e}")

# Setup paths
codette_path = Path(__file__).parent / "codette"
sys.path.insert(0, str(codette_path))
sys.path.insert(0, str(Path(__file__).parent))

# Import genre templates
try:
    from codette_genre_templates import (
        get_genre_suggestions,
        get_available_genres,
        get_genre_characteristics
    )
    GENRE_TEMPLATES_AVAILABLE = True
except ImportError:
    GENRE_TEMPLATES_AVAILABLE = False
    get_genre_suggestions = None  # type: ignore
    get_available_genres = None  # type: ignore
    get_genre_characteristics = None  # type: ignore
    print("[WARNING] Genre templates not available")

# Try to import numpy for audio analysis
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    np = None  # type: ignore
    NUMPY_AVAILABLE = False
    print("[WARNING] NumPy not available - some analysis features will be limited")

# ============================================================================
# LOGGING SETUP
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# CACHING SYSTEM FOR PERFORMANCE OPTIMIZATION
# ============================================================================

class ContextCache:
    """TTL-based cache for Supabase context retrieval (reduces API calls ~300ms per query)"""
    
    def __init__(self, ttl_seconds: int = 300):
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.ttl = ttl_seconds
        self.timestamps: Dict[str, float] = {}
        
        # Performance metrics
        self.metrics: Dict[str, Any] = {
            "hits": 0,
            "misses": 0,
            "total_requests": 0,
            "total_hit_latency_ms": 0.0,
            "total_miss_latency_ms": 0.0,
            "average_hit_latency_ms": 0.0,
            "average_miss_latency_ms": 0.0,
            "hit_rate_percent": 0.0,
            "started_at": time.time(),
        }
        self.operation_times: Dict[str, List[float]] = {
            "hits": [],
            "misses": []
        }
    
    def get_cache_key(self, message: str, filename: Optional[str]) -> str:
        """Generate cache key from message + filename"""
        key_text = f"{message}:{filename or 'none'}"
        return hashlib.md5(key_text.encode()).hexdigest()
    
    def get(self, message: str, filename: Optional[str]) -> Optional[Dict[str, Any]]:
        """Get cached context if exists and not expired"""
        start_time = time.time()
        key = self.get_cache_key(message, filename)
        self.metrics["total_requests"] += 1
        
        if key not in self.cache:
            # Cache miss
            elapsed_ms = (time.time() - start_time) * 1000
            self.metrics["misses"] += 1
            self.metrics["total_miss_latency_ms"] += elapsed_ms
            self.operation_times["misses"].append(elapsed_ms)
            logger.debug(f"Cache miss for {message[:30]}... ({elapsed_ms:.2f}ms)")
            return None
        
        # Check if expired
        age = time.time() - self.timestamps[key]
        if age > self.ttl:
            del self.cache[key]
            del self.timestamps[key]
            elapsed_ms = (time.time() - start_time) * 1000
            self.metrics["misses"] += 1
            self.metrics["total_miss_latency_ms"] += elapsed_ms
            self.operation_times["misses"].append(elapsed_ms)
            logger.debug(f"Cache expired for {message[:30]}... ({elapsed_ms:.2f}ms)")
            return None
        
        # Cache hit
        elapsed_ms = (time.time() - start_time) * 1000
        self.metrics["hits"] += 1
        self.metrics["total_hit_latency_ms"] += elapsed_ms
        self.operation_times["hits"].append(elapsed_ms)
        logger.debug(f"Cache hit for {message[:30]}... (age: {age:.1f}s, latency: {elapsed_ms:.2f}ms)")
        return self.cache[key]
    
    def set(self, message: str, filename: Optional[str], data: Dict[str, Any]) -> None:
        """Cache context data with timestamp"""
        key = self.get_cache_key(message, filename)
        self.cache[key] = data
        self.timestamps[key] = time.time()
        logger.debug(f"Cached context for {message[:30]}...")
    
    def clear(self) -> None:
        """Clear all cache"""
        self.cache.clear()
        self.timestamps.clear()
        logger.info("Context cache cleared")
    
    def _update_metrics(self) -> None:
        """Update derived metrics"""
        if self.metrics["total_requests"] > 0:
            self.metrics["hit_rate_percent"] = (
                self.metrics["hits"] / self.metrics["total_requests"] * 100
            )
        
        if self.metrics["hits"] > 0:
            self.metrics["average_hit_latency_ms"] = (
                self.metrics["total_hit_latency_ms"] / self.metrics["hits"]
            )
        
        if self.metrics["misses"] > 0:
            self.metrics["average_miss_latency_ms"] = (
                self.metrics["total_miss_latency_ms"] / self.metrics["misses"]
            )
    
    def stats(self) -> Dict[str, Any]:
        """Get comprehensive cache statistics"""
        uptime_seconds = time.time() - self.metrics["started_at"]
        self._update_metrics()
        
        return {
            "entries": len(self.cache),
            "ttl_seconds": self.ttl,
            "hits": self.metrics["hits"],
            "misses": self.metrics["misses"],
            "total_requests": self.metrics["total_requests"],
            "hit_rate_percent": round(self.metrics["hit_rate_percent"], 2),
            "average_hit_latency_ms": round(self.metrics["average_hit_latency_ms"], 2),
            "average_miss_latency_ms": round(self.metrics["average_miss_latency_ms"], 2),
            "total_hit_latency_ms": round(self.metrics["total_hit_latency_ms"], 2),
            "total_miss_latency_ms": round(self.metrics["total_miss_latency_ms"], 2),
            "uptime_seconds": round(uptime_seconds, 1),
        }

context_cache = ContextCache(ttl_seconds=300)

# ============================================================================
# FASTAPI APP SETUP
# ============================================================================

ALLOWED_ORIGINS = ["http://localhost:5173", "http://localhost:3000", "*"]

app = FastAPI(
    title="Codette AI Unified Server",
    description="Combined Codette AI server for CoreLogic Studio DAW",
    version="2.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logger.info("✅ FastAPI app created with CORS enabled")

# ============================================================================
# SUPABASE CLIENT SETUP
# ============================================================================

supabase_client = None
if SUPABASE_AVAILABLE:
    try:
        supabase_url = os.getenv('VITE_SUPABASE_URL')
        supabase_key = os.getenv('VITE_SUPABASE_ANON_KEY')
        
        if supabase_url and supabase_key:
            supabase_client = supabase.create_client(supabase_url, supabase_key)
            logger.info("✅ Supabase client connected")
        else:
            logger.warning("⚠️ Supabase credentials not found in environment variables")
    except Exception as e:
        logger.warning(f"⚠️ Failed to connect to Supabase: {e}")

# ============================================================================
# HEALTH ENDPOINTS
# ============================================================================

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "status": "ok",
        "service": "Codette AI Unified Server",
        "version": "2.0.0",
        "docs": "/docs",
    }

@app.get("/health")
async def health():
    """Health check endpoint"""
    try:
        return {
            "status": "healthy",
            "service": "Codette AI Unified Server",
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }
    except Exception as e:
        logger.error(f"ERROR in /health: {e}")
        return {"status": "error", "error": str(e)}

@app.post("/codette/chat")
async def chat_endpoint(request: dict):
    """Chat with Codette"""
    try:
        message = request.get("message", "")
        return {
            "response": f"Echo: {message}",
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }
    except Exception as e:
        logger.error(f"ERROR in /codette/chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/codette/suggest")
async def suggest_endpoint(request: dict):
    """Get AI suggestions based on context"""
    try:
        context = request.get("context", {})
        track_type = context.get("track_type", "audio")
        
        suggestions = {
            "drums": [
                {"type": "eq", "title": "Add Presence Peak", "description": "Boost 5-7kHz for punch", "confidence": 0.88},
                {"type": "compression", "title": "Tighten Transients", "description": "Ratio 4:1, Attack 5ms", "confidence": 0.85},
            ],
            "bass": [
                {"type": "eq", "title": "Clean Low-End", "description": "High-pass at 40Hz", "confidence": 0.89},
                {"type": "compression", "title": "Glue Bass", "description": "Ratio 4:1 for cohesion", "confidence": 0.87},
            ],
            "vocals": [
                {"type": "eq", "title": "De-Esser", "description": "Reduce sibilance", "confidence": 0.91},
                {"type": "compression", "title": "Control Dynamics", "description": "Ratio 2:1-4:1", "confidence": 0.89},
            ],
        }
        
        result = suggestions.get(track_type, suggestions["drums"])
        
        return {
            "success": True,
            "suggestions": result,
            "confidence": 0.85,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }
    except Exception as e:
        logger.error(f"ERROR in /codette/suggest: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for real-time updates"""
    await websocket.accept()
    logger.info("✅ WebSocket client connected")
    
    try:
        while True:
            # Receive message from client
            data = await websocket.receive_text()
            logger.debug(f"WebSocket received: {data}")
            
            # Echo back with timestamp
            response = {
                "type": "pong",
                "data": data,
                "timestamp": datetime.now(timezone.utc).isoformat(),
            }
            await websocket.send_json(response)
    except Exception as e:
        logger.warning(f"WebSocket error: {e}")
    finally:
        logger.info("❌ WebSocket client disconnected")

# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    print("\n" + "="*70)
    print("🚀 CODETTE AI UNIFIED SERVER - STARTING")
    print("="*70)
    print("📡 Server: FastAPI + Uvicorn")
    print("🔗 URL:    http://127.0.0.1:8000")
    print("📚 Docs:   http://127.0.0.1:8000/docs")
    print("="*70 + "\n")
    
    uvicorn.run(
        app,
        host="127.0.0.1",
        port=8000,
        log_level="info",
        reload=True
    )
