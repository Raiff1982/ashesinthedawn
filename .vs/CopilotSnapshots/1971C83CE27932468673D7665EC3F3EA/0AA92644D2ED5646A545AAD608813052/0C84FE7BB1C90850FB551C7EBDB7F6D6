import * as React from "react";
import type {
  Track,
  Project,
  LogicCoreMode,
  Plugin,
  Marker,
  LoopRegion,
  MetronomeSettings,
  Bus,
  MidiDevice,
  MidiRoute,
  AudioContextState,
} from "../types";
import { CodetteSuggestion } from "../lib/codetteBridge";
import { supabase } from "../lib/supabase";
import { useEffectChainAPI, EffectChainContextAPI } from "../lib/effectChainContextAdapter";
import { getAudioEngine } from "../lib/audioEngine";

// Create context (may be undefined before provider mounts)
const DAWContext = React.createContext<DAWContextType | undefined>(undefined);

interface DAWContextType {
  currentProject: Project | null;
  tracks: Track[];
  selectedTrack: Track | null;
  isPlaying: boolean;
  isRecording: boolean;
  currentTime: number;
  zoom: number;
  logicCoreMode: LogicCoreMode;
  voiceControlActive: boolean;
  cpuUsage: number;
  isUploadingFile: boolean;
  uploadError: string | null;
  deletedTracks: Track[]; // Trash
  canUndo: boolean;
  canRedo: boolean;
  markers: Marker[];
  loopRegion: LoopRegion | null;
  metronomeSettings: MetronomeSettings;
  inputLevel: number;
  latencyMs: number;
  bufferUnderruns: number;
  bufferOverruns: number;
  isAudioIOActive: boolean;
  audioIOError: string | null;
  selectedInputDevice: { label: string } | null;
  selectedInputDeviceId: string | null;
  selectedOutputDeviceId: string | null;
  selectInputDevice: (deviceId: string) => Promise<void>;
  selectOutputDevice: (deviceId: string) => Promise<void>
  getAudioContextStatus: () => AudioContextState | string;
  setCurrentProject: (project: Project | null) => void;
  togglePlay: () => void;
  toggleRecord: () => void;
  stop: () => void;
  setLogicCoreMode: (mode: LogicCoreMode) => void;
  toggleVoiceControl: () => void;
  saveProject: () => Promise<void>;
  loadProject: (projectId: string) => Promise<void>;
  uploadAudioFile: (file: File) => Promise<boolean>;
  getWaveformData: (_trackId: string) => number[];
  getAudioDuration: (_trackId: string) => number;
  getAudioBufferData: (trackId: string) => Float32Array | null;
  getAudioLevels: () => Uint8Array | null;
  seek: (timeSeconds: number) => void;
  setTrackInputGain: (trackId: string, gainDb: number) => void;
  addPluginToTrack: (trackId: string, plugin: Plugin) => void;
  removePluginFromTrack: (trackId: string, pluginId: string) => void;
  togglePluginEnabled: (
    trackId: string,
    pluginId: string,
    enabled: boolean
  ) => void;
  undo: () => void;
  redo: () => void;
  // Phase 3: Markers
  addMarker: (time: number, name: string) => void;
  deleteMarker: (markerId: string) => void;
  updateMarker: (markerId: string, updates: Partial<Marker>) => void;
  // Phase 3: Looping
  setLoopRegion: (startTime: number, endTime: number) => void;
  toggleLoop: () => void;
  clearLoopRegion: () => void;
  // Phase 3: Metronome
  toggleMetronome: () => void;
  setMetronomeVolume: (volume: number) => void;
  setMetronomeBeatSound: (sound: MetronomeSettings["beatSound"]) => void;
  // Modal State
  showNewProjectModal: boolean;
  openNewProjectModal: () => void;
  closeNewProjectModal: () => void;
  showExportModal: boolean;
  openExportModal: () => void;
  closeExportModal: () => void;
  showAudioSettingsModal: boolean;
  openAudioSettingsModal: () => void;
  closeAudioSettingsModal: () => void;
  showAboutModal: boolean;
  openAboutModal: () => void;
  closeAboutModal: () => void;
  // Additional Modals
  showSaveAsModal: boolean;
  openSaveAsModal: () => void;
  closeSaveAsModal: () => void;
  showOpenProjectModal: boolean;
  openOpenProjectModal: () => void;
  closeOpenProjectModal: () => void;
  showMidiSettingsModal: boolean;
  openMidiSettingsModal: () => void;
  closeMidiSettingsModal: () => void;
  showMixerOptionsModal: boolean;
  openMixerOptionsModal: () => void;
  closeMixerOptionsModal: () => void;
  showPreferencesModal: boolean;
  openPreferencesModal: () => void;
  closePreferencesModal: () => void;
  showShortcutsModal: boolean;
  openShortcutsModal: () => void;
  closeShortcutsModal: () => void;
  // Export
  exportAudio: (format: string, quality: string) => Promise<void>;
  // Project Import/Export
  exportProjectAsFile: () => void;
  importProjectFromFile: () => Promise<void>;
  // Bus/Routing functions
  buses: Bus[];
  createBus: (name: string) => void;
  deleteBus: (busId: string) => void;
  addTrackToBus: (trackId: string, busId: string) => void;
  removeTrackFromBus: (trackId: string, busId: string) => void;
  createSidechain: (sourceTrackId: string, targetTrackId: string) => void;
  // Plugin functions
  loadPlugin: (trackId: string, pluginName: string) => void;
  unloadPlugin: (trackId: string, pluginId: string) => void;
  loadedPlugins: Map<string, Plugin[]>;
  // MIDI functions
  midiDevices: MidiDevice[];
  createMIDIRoute: (sourceDeviceId: string, targetTrackId: string) => void;
  deleteMIDIRoute: (routeId: string) => void;
  getMIDIRoutesForTrack: (trackId: string) => MidiRoute[];
  // Codette AI Integration (Phase 1)
  codetteConnected: boolean;
  codetteLoading: boolean;
  codetteSuggestions: CodetteSuggestion[];
  getSuggestionsForTrack: (
    trackId: string,
    context?: string
  ) => Promise<CodetteSuggestion[]>;
  applyCodetteSuggestion: (
    trackId: string,
    suggestion: CodetteSuggestion
  ) => Promise<boolean>;
  analyzeTrackWithCodette: (trackId: string) => Promise<any>;
  syncDAWStateToCodette: () => Promise<boolean>;
  // Codette Transport Control (Phase 3)
  codetteTransportPlay: () => Promise<any>;
  codetteTransportStop: () => Promise<any>;
  codetteTransportSeek: (timeSeconds: number) => Promise<any>;
  codetteSetTempo: (bpm: number) => Promise<any>;
  codetteSetLoop: (
    enabled: boolean,
    startTime?: number,
    endTime?: number
  ) => Promise<any>;
  // WebSocket Status (Phase 4)
  getWebSocketStatus: () => { connected: boolean; reconnectAttempts: number };
  getCodetteBridgeStatus: () => {
    connected: boolean;
    reconnectCount: number;
    isReconnecting: boolean;
  };
  // Clipboard Operations
  clipboardData: { type: 'track' | 'clip' | null; data: any | null };
  cutTrack: (trackId: string) => void;
  copyTrack: (trackId: string) => void;
  pasteTrack: () => void;
  selectAllTracks: () => void;
  deselectAllTracks: () => void;
  selectedTracks: Set<string>;
  // Utility
  cpuUsageDetailed: Record<string, number>;

  // Recording state (NEW)
  recordingTrackId: null | string;
  recordingStartTime: number;
  recordingTakeCount: number;
  recordingMode: 'audio' | 'midi' | 'overdub';
  punchInEnabled: boolean;
  punchInTime: number;
  punchOutTime: number;
  recordingBlob: Blob | null;
  recordingError: string | null;
  
  // Recording methods (NEW)
  startRecording: (trackId: string) => Promise<boolean>;
  stopRecording: () => Promise<Blob | null>;
  pauseRecording: () => boolean;
  resumeRecording: () => boolean;
  setRecordingMode: (mode: 'audio' | 'midi' | 'overdub') => void;
  setPunchInOut: (punchIn: number, punchOut: number) => void;
  togglePunchIn: () => void;
  undoLastRecording: () => void;

  // Phase 9: Effect Chain Management (from EffectChainContextAPI)
  effectChainsByTrack: EffectChainContextAPI['effectChainsByTrack'];
  getTrackEffects: EffectChainContextAPI['getTrackEffects'];
  addEffectToTrack: EffectChainContextAPI['addEffectToTrack'];
  removeEffectFromTrack: EffectChainContextAPI['removeEffectFromTrack'];
  updateEffectParameter: EffectChainContextAPI['updateEffectParameter'];
  enableDisableEffect: EffectChainContextAPI['enableDisableEffect'];
  setEffectWetDry: EffectChainContextAPI['setEffectWetDry'];
  getEffectChainForTrack: EffectChainContextAPI['getEffectChainForTrack'];
  processTrackEffects: EffectChainContextAPI['processTrackEffects'];
  hasActiveEffects: EffectChainContextAPI['hasActiveEffects'];

  // NEW: Track management methods
  addTrack: (type: Track["type"]) => void;
  selectTrack: (trackId: string) => void;
  updateTrack: (trackId: string, updates: Partial<Track>) => void;
  deleteTrack: (trackId: string) => void;
  duplicateTrack: (trackId: string) => Promise<Track | null>;
  restoreTrack: (trackId: string) => void;
  permanentlyDeleteTrack: (trackId: string) => void;
}

// DAW Provider component
export function DAWProvider({ children }: { children: React.ReactNode }) {
  // Get AudioEngine singleton (stable across renders)
  const audioEngineRef = React.useRef(getAudioEngine());
  const audioEngineInitializedRef = React.useRef(false);

  // Initialize AudioEngine on mount
  React.useEffect(() => {
    if (!audioEngineInitializedRef.current) {
      audioEngineRef.current
        .initialize()
        .then(() => {
          console.log("[DAWContext] AudioEngine initialized successfully");
          audioEngineInitializedRef.current = true;
        })
        .catch((error) => {
          console.error("[DAWContext] Failed to initialize AudioEngine:", error);
        });
    }
  }, []);

  // State and context initialization
  const [currentProject, setCurrentProject] = React.useState<Project | null>(null);
  const [tracks, setTracks] = React.useState<Track[]>([]);
  const [selectedTrack, setSelectedTrack] = React.useState<Track | null>(null);
  const [isPlaying, setIsPlaying] = React.useState<boolean>(false);
  const [isRecording, setIsRecording] = React.useState<boolean>(false);
  const [currentTime, setCurrentTime] = React.useState<number>(0);
  const [zoom, _setZoom] = React.useState<number>(1);
  const [logicCoreMode, setLogicCoreMode] = React.useState<LogicCoreMode>("ON");
  const [voiceControlActive, setVoiceControlActive] = React.useState<boolean>(false);
  const [cpuUsage, _setCpuUsage] = React.useState<number>(0);
  const [isUploadingFile, setIsUploadingFile] = React.useState<boolean>(false);
  const [uploadError, setUploadError] = React.useState<string | null>(null);
  const [deletedTracks, _setDeletedTracks] = React.useState<Track[]>([]);
  const [canUndo, _setCanUndo] = React.useState<boolean>(false);
  const [canRedo, _setCanRedo] = React.useState<boolean>(false);
  const [markers, _setMarkers] = React.useState<Marker[]>([]);
  const [loopRegion, _setLoopRegion] = React.useState<LoopRegion | null>(null);
  const [metronomeSettings, _setMetronomeSettings] = React.useState<MetronomeSettings>({
    enabled: false,
    volume: 1,
    beatSound: "click",
    accentFirst: false,
  });

  // Audio I/O State - Real device management
  const [selectedInputDeviceId, _setSelectedInputDeviceId] = React.useState<string | null>(null);
  const [selectedOutputDeviceId, _setSelectedOutputDeviceId] = React.useState<string | null>(null);
  const [inputLevel, _setInputLevel] = React.useState<number>(0);
  const [latencyMs, _setLatencyMs] = React.useState<number>(0);
  const [bufferUnderruns, _setBufferUnderruns] = React.useState<number>(0);
  const [bufferOverruns, _setBufferOverruns] = React.useState<number>(0);
  const [isAudioIOActive, _setIsAudioIOActive] = React.useState<boolean>(false);
  const [audioIOError, _setAudioIOError] = React.useState<string | null>(null);

  // MIDI State
  const [midiDevices] = React.useState<MidiDevice[]>([]);
  
  // Phase 9: Effect Chain API
  const effectChainAPI = useEffectChainAPI();
  
  // Recording state (NEW)
  const [recordingTrackId, _setRecordingTrackId] = React.useState<string | null>(null);
  const [recordingStartTime, _setRecordingStartTime] = React.useState<number>(0);
  const [recordingTakeCount, setRecordingTakeCount] = React.useState<number>(0);
  const [recordingModeState, setRecordingModeState] = React.useState<'audio' | 'midi' | 'overdub'>('audio');
  const [punchInEnabled, _setPunchInEnabled] = React.useState<boolean>(false);
  const [punchInTime, _setPunchInTime] = React.useState<number>(0);
  const [punchOutTime, _setPunchOutTime] = React.useState<number>(0);
  const [recordingBlob, _setRecordingBlob] = React.useState<Blob | null>(null);
  const [recordingError, _setRecordingError] = React.useState<string | null>(null);

  // WebSocket Status (Phase 4)
  const [webSocketStatus, _setWebSocketStatus] = React.useState<{ connected: boolean; reconnectAttempts: number }>({
    connected: false,
    reconnectAttempts: 0,
  });

  // Modal State Management (NEW)
  const [showNewProjectModal, setShowNewProjectModal] = React.useState<boolean>(false);
  const [showExportModal, setShowExportModal] = React.useState<boolean>(false);
  const [showAudioSettingsModal, setShowAudioSettingsModal] = React.useState<boolean>(false);
  const [showAboutModal, setShowAboutModal] = React.useState<boolean>(false);
  const [showSaveAsModal, setShowSaveAsModal] = React.useState<boolean>(false);
  const [showOpenProjectModal, setShowOpenProjectModal] = React.useState<boolean>(false);
  const [showMidiSettingsModal, setShowMidiSettingsModal] = React.useState<boolean>(false);
  const [showMixerOptionsModal, setShowMixerOptionsModal] = React.useState<boolean>(false);
  const [showPreferencesModal, setShowPreferencesModal] = React.useState<boolean>(false);
  const [showShortcutsModal, setShowShortcutsModal] = React.useState<boolean>(false);

  // Bus and MIDI routing state (NEW)
  const [buses, setBuses] = React.useState<Bus[]>([]);
  const [midiRoutes, setMidiRoutes] = React.useState<MidiRoute[]>([]);
  const [selectedTracks, setSelectedTracks] = React.useState<Set<string>>(new Set());
  const [clipboardData, setClipboardData] = React.useState<{ type: 'track' | 'clip' | null; data: any | null }>({ type: null, data: null });


  // Unique ID counter to prevent React key collisions
  const trackIdCounterRef = React.useRef<number>(0);
  const markerIdCounterRef = React.useRef<number>(0);

  const getUniqueTrackId = () => `track-${++trackIdCounterRef.current}`;
  const getUniqueMarkerId = () => `marker-${Date.now()}-${++markerIdCounterRef.current}`;

  // Simple playback timer
  const playTimerRef = React.useRef<number | null>(null);
  const lastTickRef = React.useRef<number | null>(null);

  React.useEffect(() => {
    if (isPlaying) {
      lastTickRef.current = performance.now();
      const tick = () => {
        const now = performance.now();
        const last = lastTickRef.current ?? now;
        const deltaSec = (now - last) / 1000;
        lastTickRef.current = now;
        setCurrentTime((prev) => prev + deltaSec);
        playTimerRef.current = requestAnimationFrame(tick);
      };
      playTimerRef.current = requestAnimationFrame(tick);
    } else if (playTimerRef.current) {
      cancelAnimationFrame(playTimerRef.current);
      playTimerRef.current = null;
      lastTickRef.current = null;
    }
    return () => {
      if (playTimerRef.current) {
        cancelAnimationFrame(playTimerRef.current);
        playTimerRef.current = null;
      }
    };
  }, [isPlaying]);

  // Demo waveform and duration cache (stable across renders)
  const waveformCacheRef = React.useRef<Map<string, number[]>>(new Map());
  const durationCacheRef = React.useRef<Map<string, number>>(new Map());

  const ensureDemoDataForTrack = (trackId: string) => {
    if (!waveformCacheRef.current.has(trackId)) {
      const length = 4096;
      const data = Array.from({ length }, (_, i) => {
        const t = (i / length) * Math.PI * 4;
        return Math.abs(Math.sin(t) * 0.6 + Math.sin(t * 2) * 0.3 + Math.sin(t * 3) * 0.1 + Math.random() * 0.05);
      });
      waveformCacheRef.current.set(trackId, data);
    }
    if (!durationCacheRef.current.has(trackId)) {
      durationCacheRef.current.set(trackId, 60); // default 60s
    }
  };

  const getAudioContextStatus = () => {
    return "running";
  };

  const togglePlay = () => {
    setIsPlaying((prev) => !prev);
  };

  const toggleRecord = () => {
    setIsRecording((prev) => !prev);
  };

  const stop = () => {
    setIsPlaying(false);
    setIsRecording(false);
    setCurrentTime(0);
  };

  const saveProject = async () => {
    if (!currentProject) return;
    setIsUploadingFile(true);
    try {
      await supabase
        .from("projects")
        .insert([{ ...currentProject, id: undefined }])
        .single();
      setCurrentProject(currentProject);
    } catch (error) {
      console.error("Error saving project:", error);
      setUploadError("Error saving project. Please try again.");
    } finally {
      setIsUploadingFile(false);
    }
  };

  const loadProject = async (projectId: string) => {
    setIsUploadingFile(true);
    try {
      const { data, error } = await supabase
        .from("projects")
        .select("*")
        .eq("id", projectId)
        .single();

      if (error) throw error;

      setCurrentProject(data);
    } catch (error) {
      console.error("Error loading project:", error);
      setUploadError("Error loading project. Please try again.");
    } finally {
      setIsUploadingFile(false);
    }
  };

  // NEW: Upload audio file and load into AudioEngine
  const uploadAudioFile = async (file: File): Promise<boolean> => {
    if (!selectedTrack) {
      setUploadError("Please select a track first");
      return false;
    }

    // Validate file type
    const validTypes = ["audio/mpeg", "audio/wav", "audio/ogg", "audio/flac", "audio/aac"];
    if (!validTypes.includes(file.type) && !file.name.match(/\.(mp3|wav|ogg|flac|aac)$/i)) {
      setUploadError("Unsupported audio format. Use MP3, WAV, OGG, FLAC, or AAC.");
      return false;
    }

    // Validate file size (100MB max)
    const maxSize = 100 * 1024 * 1024;
    if (file.size > maxSize) {
      setUploadError("File too large. Maximum size is 100MB.");
      return false;
    }

    setIsUploadingFile(true);
    setUploadError(null);

    try {
      // Load audio file into AudioEngine
      const success = await audioEngineRef.current.loadAudioFile(selectedTrack.id, file);
      
      if (!success) {
        setUploadError("Failed to decode audio file");
        return false;
      }

      // Cache waveform and duration from AudioEngine
      const waveform = audioEngineRef.current.getWaveformData(selectedTrack.id);
      const duration = audioEngineRef.current.getAudioDuration(selectedTrack.id);
      
      waveformCacheRef.current.set(selectedTrack.id, waveform);
      durationCacheRef.current.set(selectedTrack.id, duration);

      console.log(
        `[DAWContext] Audio file loaded: ${duration.toFixed(2)}s, ${waveform.length} waveform samples`
      );

      return true;
    } catch (error) {
      console.error("Error uploading audio file:", error);
      setUploadError(error instanceof Error ? error.message : "Unknown error occurred");
      return false;
    } finally {
      setIsUploadingFile(false);
    }
  };

  // NEW: Get waveform data from AudioEngine (with fallback to cache)
  const getWaveformData = (trackId: string): number[] => {
    // Try AudioEngine first
    try {
      const waveform = audioEngineRef.current.getWaveformData(trackId);
      if (waveform && waveform.length > 0) {
        return waveform;
      }
    } catch (error) {
      console.debug("[DAWContext] AudioEngine waveform retrieval failed:", error);
    }

    // Fall back to local cache
    return waveformCacheRef.current.get(trackId) || [];
  };

  // NEW: Get audio duration from AudioEngine (with fallback to cache)
  const getAudioDuration = (trackId: string): number => {
    // Try AudioEngine first
    try {
      const duration = audioEngineRef.current.getAudioDuration(trackId);
      if (duration > 0) {
        return duration;
      }
    } catch (error) {
      console.debug("[DAWContext] AudioEngine duration retrieval failed:", error);
    }

    // Fall back to local cache
    return durationCacheRef.current.get(trackId) || 0;
  };

  // NEW: Get audio buffer data from AudioEngine
  const getAudioBufferData = (trackId: string): Float32Array | null => {
    try {
      return audioEngineRef.current.getAudioBufferData(trackId);
    } catch (error) {
      console.debug("[DAWContext] AudioEngine buffer retrieval failed:", error);
      return null;
    }
  };

  // Sync DAW state to Codette AI (Phase 1)
  const syncDAWStateToCodette = async () => {
    return true;
  };

  // Codette Transport Control (Phase 3)
  const codetteTransportPlay = async () => {};
  const codetteTransportStop = async () => {};
  const codetteTransportSeek = async (_timeSeconds: number) => {};
  const codetteSetTempo = async (_bpm: number) => {};
  const codetteSetLoop = async (
    _enabled: boolean,
    _startTime?: number,
    _endTime?: number
  ) => {};

  const cutTrack = (_trackId: string) => {};
  const copyTrack = (_trackId: string) => {};
  const pasteTrack = () => {};
  const selectAllTracks = () => {};
  const deselectAllTracks = () => {};

  const startRecording = async (_trackId: string) => {
    return true;
  };
  const stopRecording = async () => {
    return null;
  };
  const pauseRecording = () => {
    return true;
  };
  const resumeRecording = () => {
    return true;
  };
  const setRecordingMode = (mode: 'audio' | 'midi' | 'overdub') => {
    setRecordingModeState(mode);
  };
  const setPunchInOut = (_punchIn: number, _punchOut: number) => {};
  const togglePunchIn = () => {};
  const undoLastRecording = () => {
    console.log("Undo last recording action");
    setRecordingTakeCount((prev: number) => Math.max(0, prev - 1));
  };

  const toggleVoiceControl = () => setVoiceControlActive((prev) => !prev);
  const undo = () => { console.log("undo"); };
  const redo = () => { console.log("redo"); };

  const contextValue: DAWContextType = {
    currentProject,
    tracks,
    selectedTrack,
    isPlaying,
    isRecording,
    currentTime,
    zoom,
    logicCoreMode,
    voiceControlActive,
    cpuUsage,
    isUploadingFile,
    uploadError,
    deletedTracks,
    canUndo,
    canRedo,
    markers,
    loopRegion,
    metronomeSettings,
    inputLevel,
    latencyMs,
    bufferUnderruns,
    bufferOverruns,
    isAudioIOActive,
    audioIOError,
    selectedInputDevice: null,
    selectedInputDeviceId,
    selectedOutputDeviceId,
    selectInputDevice: async (deviceId: string) => { _setSelectedInputDeviceId(deviceId); },
    selectOutputDevice: async (deviceId: string) => { _setSelectedOutputDeviceId(deviceId); },
    getAudioContextStatus,
    setCurrentProject,
    togglePlay,
    toggleRecord,
    stop,
    setLogicCoreMode: (mode: LogicCoreMode) => setLogicCoreMode(mode),
    toggleVoiceControl,
    saveProject,
    loadProject,
    uploadAudioFile,
    getWaveformData,
    getAudioDuration,
    getAudioBufferData,
    getAudioLevels: () => null,
    seek: () => {},
    setTrackInputGain: () => {},
    addPluginToTrack: () => {},
    removePluginFromTrack: () => {},
    togglePluginEnabled: () => {},
    undo,
    redo,
    addTrack: (type: Track["type"]) => {
      const t: Track = {
        id: getUniqueTrackId(),
        name: `${type} ${tracks.length + 1}`,
        type,
        color: '#888',
        muted: false,
        soloed: false,
        armed: false,
        inputGain: 0,
        volume: 0,
        pan: 0,
        stereoWidth: 100,
        phaseFlip: false,
        inserts: [],
        sends: [],
        routing: '',
      };
      setTracks((prev) => [...prev, t]);
      // Prepare demo data for new track (stable reference)
      ensureDemoDataForTrack(t.id);
    },
    selectTrack: (trackId: string) => {
      const t = tracks.find((tr) => tr.id === trackId) || null;
      setSelectedTrack(t);
      if (t) ensureDemoDataForTrack(t.id);
    },
    updateTrack: (trackId: string, updates: Partial<Track>) => {
      setTracks((prev) => prev.map((t) => (t.id === trackId ? { ...t, ...updates } : t)));
    },
    deleteTrack: (trackId: string) => {
      setTracks((prev) => prev.filter((t) => t.id !== trackId));
      const del = tracks.find((t) => t.id === trackId);
      if (del) _setDeletedTracks((prev) => [...prev, del]);
    },
    duplicateTrack: async (trackId: string) => {
      const source = tracks.find((t) => t.id === trackId);
      if (!source) return null;
      const copy: Track = { ...source, id: getUniqueTrackId() };
      setTracks((prev) => [...prev, copy]);
      
      // Duplicate audio buffer in AudioEngine
      await audioEngineRef.current.duplicateTrackAudioBuffer(source.id, copy.id);
      
      // Copy cached data
      const wf = waveformCacheRef.current.get(source.id);
      if (wf) waveformCacheRef.current.set(copy.id, wf);
      const dur = durationCacheRef.current.get(source.id);
      if (dur) durationCacheRef.current.set(copy.id, dur);
      return copy;
    },
    restoreTrack: (trackId: string) => {
      const t = deletedTracks.find((tr) => tr.id === trackId);
      if (!t) return;
      setTracks((prev) => [...prev, { ...t, deleted: false }]);
      _setDeletedTracks((prev) => prev.filter((tr) => tr.id !== trackId));
    },
    permanentlyDeleteTrack: (trackId: string) => {
      _setDeletedTracks((prev) => prev.filter((tr) => tr.id !== trackId));
    },
    addMarker: (time: number, name: string) => {
      const marker: Marker = { id: getUniqueMarkerId(), name, time, color: '#fff', locked: false };
      _setMarkers((prev) => [...prev, marker]);
    },
    deleteMarker: (markerId: string) => {
      _setMarkers((prev) => prev.filter((m) => m.id !== markerId));
    },
    updateMarker: (markerId: string, updates: Partial<Marker>) => {
      _setMarkers((prev) => prev.map((m) => (m.id === markerId ? { ...m, ...updates } : m)));
    },
    setLoopRegion: (startTime: number, endTime: number) => {
      _setLoopRegion({ enabled: loopRegion?.enabled ?? true, startTime, endTime });
    },
    toggleLoop: () => {
      if (!loopRegion) return;
      const enabled = loopRegion.enabled;
      _setLoopRegion((prev) => (prev ? { ...prev, enabled: !enabled } : prev));
    },
    clearLoopRegion: () => {
      _setLoopRegion(null);
    },
    toggleMetronome: () => {
      _setMetronomeSettings((prev) => ({ ...prev, enabled: !prev.enabled }));
    },
    setMetronomeVolume: (volume: number) => {
      _setMetronomeSettings((prev) => ({ ...prev, volume }));
    },
    setMetronomeBeatSound: (sound: MetronomeSettings["beatSound"]) => {
      _setMetronomeSettings((prev) => ({ ...prev, beatSound: sound }));
    },
    openNewProjectModal: () => {},
    closeNewProjectModal: () => {},
    openExportModal: () => {},
    closeExportModal: () => {},
    openAudioSettingsModal: () => {},
    closeAudioSettingsModal: () => {},
    openAboutModal: () => {},
    closeAboutModal: () => {},
    openSaveAsModal: () => {},
    closeSaveAsModal: () => {},
    openOpenProjectModal: () => {},
    closeOpenProjectModal: () => {},
    openMidiSettingsModal: () => {},
    closeMidiSettingsModal: () => {},
    openMixerOptionsModal: () => {},
    closeMixerOptionsModal: () => {},
    openPreferencesModal: () => {},
    closePreferencesModal: () => {},
    openShortcutsModal: () => {},
    closeShortcutsModal: () => {},
    exportAudio: async (_format: string, _quality: string) => {},
    exportProjectAsFile: () => {},
    importProjectFromFile: async () => {},
    buses: [],
    createBus: (_name: string) => {},
    deleteBus: (_busId: string) => {},
    addTrackToBus: (_trackId: string, _busId: string) => {},
    removeTrackFromBus: (_trackId: string, _busId: string) => {},
    createSidechain: (_sourceTrackId: string, _targetTrackId: string) => {},
    loadPlugin: (_trackId: string, _pluginName: string) => {},
    unloadPlugin: (_trackId: string, _pluginId: string) => {},
    midiDevices,
    createMIDIRoute: (_sourceDeviceId: string, _targetTrackId: string) => {},
    deleteMIDIRoute: (_routeId: string) => {},
    getMIDIRoutesForTrack: (_trackId: string) => [],
    codetteConnected: false,
    codetteLoading: false,
    codetteSuggestions: [],
    getSuggestionsForTrack: async () => [],
    applyCodetteSuggestion: async () => true,
    analyzeTrackWithCodette: async () => ({}),
    syncDAWStateToCodette: async () => true,
    codetteTransportPlay,
    codetteTransportStop,
    codetteTransportSeek,
    codetteSetTempo,
    codetteSetLoop,
    getWebSocketStatus: () => webSocketStatus,
    getCodetteBridgeStatus: () => ({
      connected: false,
      reconnectCount: 0,
      isReconnecting: false,
    }),
    clipboardData: { type: null, data: null },
    cutTrack,
    copyTrack,
    pasteTrack,
    selectAllTracks,
    deselectAllTracks,
    selectedTracks: new Set<string>(),
    cpuUsageDetailed: {},
    recordingTrackId,
    recordingStartTime,
    recordingTakeCount,
    recordingMode: recordingModeState,
    punchInEnabled,
    punchInTime,
    punchOutTime,
    recordingBlob,
    recordingError,
    startRecording,
    stopRecording,
    pauseRecording,
    resumeRecording,
    setRecordingMode,
    setPunchInOut,
    togglePunchIn,
    undoLastRecording,
    effectChainsByTrack: effectChainAPI.effectChainsByTrack,
    getTrackEffects: effectChainAPI.getTrackEffects,
    addEffectToTrack: effectChainAPI.addEffectToTrack,
    removeEffectFromTrack: effectChainAPI.removeEffectFromTrack,
    updateEffectParameter: effectChainAPI.updateEffectParameter,
    enableDisableEffect: effectChainAPI.enableDisableEffect,
    setEffectWetDry: effectChainAPI.setEffectWetDry,
    getEffectChainForTrack: effectChainAPI.getEffectChainForTrack,
    processTrackEffects: effectChainAPI.processTrackEffects,
    hasActiveEffects: effectChainAPI.hasActiveEffects,
    loadedPlugins: new Map(),
    showNewProjectModal,
    showExportModal,
    showAudioSettingsModal,
    showAboutModal,
    showSaveAsModal,
    showOpenProjectModal,
    showMidiSettingsModal,
    showMixerOptionsModal,
    showPreferencesModal,
    showShortcutsModal,
  };

  return <DAWContext.Provider value={contextValue}>{children}</DAWContext.Provider>;
}

// Custom hook to use DAW context
export function useDAW() {
  const context = React.useContext(DAWContext);
  if (!context) {
    throw new Error("useDAW must be used within a DAWProvider");
  }
  return context;
}
