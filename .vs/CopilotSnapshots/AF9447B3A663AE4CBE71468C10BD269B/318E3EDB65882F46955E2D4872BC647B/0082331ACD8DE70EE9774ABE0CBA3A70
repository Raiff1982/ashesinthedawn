import logging
import nltk
import numpy as np
import sympy as sp
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import re
from typing import List, Dict, Any, Optional
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.tag import pos_tag
from nltk.corpus import wordnet
import random
import os
import json
from datetime import datetime

logger = logging.getLogger(__name__)

# Try to import Supabase (optional dependency)
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    logger.warning("Supabase not available - install with: pip install supabase")

# Download required NLTK data with error handling
try:
    nltk.download('punkt', quiet=True)
    nltk.download('averaged_perceptron_tagger', quiet=True)
    nltk.download('wordnet', quiet=True)
except Exception as e:
    logger.warning(f"NLTK download failed (this is non-critical): {e}")

class Codette:
    def __init__(self, user_name="User"):
        self.user_name = user_name
        self.memory = []
        self.analyzer = SentimentIntensityAnalyzer()
        np.seterr(divide='ignore', invalid='ignore')
        self.audit_log("Codette initialized", system=True)
        self.context_memory = []
        
        # DAW-specific knowledge base
        self.daw_knowledge = self._initialize_daw_knowledge()
        
        # Response variation tracking to prevent repetition
        self.recent_responses = []
        self.max_recent_responses = 20
        
        # Personality modes for response variation
        self.personality_modes = [
            'technical_expert',     # Precise, technical, professional
            'creative_mentor',      # Inspirational, metaphorical, encouraging
            'practical_guide',      # Direct, actionable, efficient
            'analytical_teacher',   # Detailed, explanatory, educational
            'innovative_explorer'   # Experimental, cutting-edge, forward-thinking
        ]
        self.current_personality = 'technical_expert'
        
        # Conversation context (recent topics)
        self.conversation_topics = []
        self.max_conversation_topics = 10
        
        # Existing table tracking
        self.has_music_knowledge_table = False
        self.has_music_knowledge_backup_table = False
        self.has_chat_history_table = False
        self.music_knowledge_table = 'music_knowledge'  # Default, may switch to backup
        
        # Initialize Supabase client (if available)
        self.supabase_client = self._initialize_supabase()
        
    def _initialize_supabase(self) -> Optional[Any]:
        """Initialize Supabase client for persistent storage"""
        if not SUPABASE_AVAILABLE:
            logger.info("Codette running without Supabase integration")
            return None
        
        try:
            supabase_url = os.getenv('VITE_SUPABASE_URL')
            supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY') or os.getenv('VITE_SUPABASE_ANON_KEY')
            
            if supabase_url and supabase_key:
                client = create_client(supabase_url, supabase_key)
                logger.info("? Codette connected to Supabase for persistent knowledge")
                
                # Test connection to existing tables
                try:
                    # Check for music_knowledge table (primary)
                    response = client.table('music_knowledge').select('*').limit(1).execute()
                    if response.data is not None:
                        logger.info("? Found existing music_knowledge table (primary)")
                        self.has_music_knowledge_table = True
                        self.music_knowledge_table = 'music_knowledge'
                    
                    # Check for music_knowledge_dedupe_backup table (backup)
                    response = client.table('music_knowledge_dedupe_backup').select('*').limit(1).execute()
                    if response.data is not None:
                        logger.info("? Found existing music_knowledge_dedupe_backup table (backup)")
                        self.has_music_knowledge_backup_table = True
                        # Use primary if both exist, otherwise use backup
                        if not self.has_music_knowledge_table:
                            self.music_knowledge_table = 'music_knowledge_dedupe_backup'
                            self.has_music_knowledge_table = True
                    
                    # Check if chat_history exists
                    response = client.table('chat_history').select('*').limit(1).execute()
                    if response.data is not None:
                        logger.info("? Found existing chat_history table")
                        self.has_chat_history_table = True
                except Exception as check_error:
                    logger.debug(f"Table check: {check_error}")
                
                return client
            else:
                logger.info("Codette running without Supabase (credentials not configured)")
                return None
        except Exception as e:
            logger.warning(f"Codette Supabase init failed (non-critical): {e}")
            return None
    
    def save_conversation_to_db(self, prompt: str, response: str, metadata: Optional[Dict[str, Any]] = None):
        """Save conversation to Supabase for learning and context"""
        if not self.supabase_client:
            return
        
        try:
            conversation_entry = {
                'user_name': self.user_name,
                'prompt': prompt,
                'response': response,
                'personality_mode': self.current_personality,
                'metadata': metadata or {},
                'created_at': datetime.utcnow().isoformat()
            }
            
            # Insert into codette_conversations table
            self.supabase_client.table('codette_conversations').insert(conversation_entry).execute()
            logger.debug(f"Saved conversation to Supabase: {prompt[:50]}...")
        except Exception as e:
            logger.debug(f"Failed to save conversation (non-critical): {e}")
    
    def get_conversation_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Retrieve recent conversation history from Supabase"""
        if not self.supabase_client:
            return []
        
        try:
            response = self.supabase_client.table('codette_conversations') \
                .select('*') \
                .eq('user_name', self.user_name) \
                .order('created_at', desc=True) \
                .limit(limit) \
                .execute()
            
            return response.data if response.data else []
        except Exception as e:
            logger.debug(f"Failed to retrieve conversation history: {e}")
            return []
    
    def rotate_personality(self):
        """Rotate personality mode for response variation"""
        current_index = self.personality_modes.index(self.current_personality)
        next_index = (current_index + 1) % len(self.personality_modes)
        self.current_personality = self.personality_modes[next_index]
        logger.debug(f"Codette personality rotated to: {self.current_personality}")
    
    def get_personality_prefix(self) -> str:
        """Get response prefix based on personality mode"""
        prefixes = {
            'technical_expert': '[Technical Expert]',
            'creative_mentor': '[Creative Mentor]',
            'practical_guide': '[Practical Guide]',
            'analytical_teacher': '[Audio Engineer]',
            'innovative_explorer': '[Innovation Lab]'
        }
        return prefixes.get(self.current_personality, '[DAW Expert]')
        
    def _initialize_daw_knowledge(self) -> Dict[str, Any]:
        """Initialize DAW-specific knowledge base for intelligent suggestions"""
        return {
            'frequency_ranges': {
                'sub_bass': {'min': 20, 'max': 60, 'desc': 'Physical punch and power'},
                'bass': {'min': 60, 'max': 250, 'desc': 'Fundamental low-end warmth'},
                'low_mids': {'min': 250, 'max': 500, 'desc': 'Body and fullness'},
                'mids': {'min': 500, 'max': 2000, 'desc': 'Core tonal character'},
                'upper_mids': {'min': 2000, 'max': 4000, 'desc': 'Presence and definition'},
                'highs': {'min': 4000, 'max': 8000, 'desc': 'Clarity and articulation'},
                'air': {'min': 8000, 'max': 20000, 'desc': 'Sparkle and openness'}
            },
            'track_types': {
                'audio': {
                    'common_issues': ['phase problems', 'muddy low-end', 'harsh highs', 'lack of presence'],
                    'mixing_tips': [
                        'Use high-pass filter to remove unnecessary low frequencies',
                        'Apply gentle EQ to enhance the natural tone',
                        'Use compression to control dynamics',
                        'Add subtle reverb for spatial depth'
                    ]
                },
                'instrument': {
                    'common_issues': ['timing inconsistencies', 'velocity variations', 'quantization artifacts'],
                    'mixing_tips': [
                        'Humanize MIDI velocity for natural feel',
                        'Layer multiple synth patches for richness',
                        'Use sidechain compression with kick/bass',
                        'Apply stereo widening carefully'
                    ]
                },
                'vocals': {
                    'common_issues': ['sibilance', 'breath noise', 'inconsistent volume', 'lack of air'],
                    'mixing_tips': [
                        'De-ess harsh frequencies (6-8kHz)',
                        'Boost presence around 3-5kHz',
                        'Add air with gentle 10-12kHz boost',
                        'Use compression (3:1 to 6:1 ratio)',
                        'Double-track for width and depth'
                    ]
                },
                'drums': {
                    'common_issues': ['weak kick', 'thin snare', 'muddy mix', 'lack of punch'],
                    'mixing_tips': [
                        'High-pass individual drums except kick and snare',
                        'Boost kick fundamental (50-100Hz)',
                        'Add snare crack at 3-5kHz',
                        'Use parallel compression for power',
                        'Pan toms and cymbals for stereo width'
                    ]
                }
            },
            'mixing_principles': {
                'gain_staging': {
                    'target_peak': -6,  # dB
                    'target_rms': -18,  # dB
                    'headroom': 6,  # dB for mastering
                    'description': 'Proper gain staging prevents clipping and maintains headroom'
                },
                'eq_guidelines': {
                    'cut_before_boost': True,
                    'narrow_q_for_cuts': True,
                    'wide_q_for_boosts': True,
                    'description': 'Subtractive EQ is more transparent than additive'
                },
                'compression': {
                    'attack_fast': {'range': [1, 10], 'unit': 'ms', 'use': 'control transients'},
                    'attack_slow': {'range': [20, 50], 'unit': 'ms', 'use': 'preserve transients'},
                    'release_fast': {'range': [50, 150], 'unit': 'ms', 'use': 'pumping effect'},
                    'release_auto': {'description': 'adapts to signal, most transparent'},
                    'ratio_light': {'range': [2, 3], 'use': 'subtle control'},
                    'ratio_heavy': {'range': [6, 10], 'use': 'aggressive control'}
                },
                'panning': {
                    'center': ['kick', 'snare', 'bass', 'lead_vocal'],
                    'wide': ['guitars', 'backing_vocals', 'synth_pads'],
                    'extreme': ['percussion', 'effects', 'ear_candy']
                }
            },
            'genre_characteristics': {
                'electronic': {
                    'key_elements': ['tight low-end', 'wide synths', 'punchy drums', 'automated filters'],
                    'typical_bpm': [120, 140],
                    'mixing_focus': 'clarity in high-energy sections'
                },
                'hip_hop': {
                    'key_elements': ['dominant bass', 'crisp drums', 'clear vocals', 'rhythmic elements'],
                    'typical_bpm': [80, 100],
                    'mixing_focus': 'vocal presence and low-end power'
                },
                'rock': {
                    'key_elements': ['distorted guitars', 'live drums', 'dynamic range', 'raw energy'],
                    'typical_bpm': [100, 140],
                    'mixing_focus': 'balance between power and clarity'
                },
                'pop': {
                    'key_elements': ['polished vocals', 'layered instruments', 'radio-ready sound', 'hooks'],
                    'typical_bpm': [100, 130],
                    'mixing_focus': 'commercial loudness and clarity'
                }
            },
            'common_problems': {
                'muddy_mix': {
                    'causes': ['low-mid buildup', 'too much reverb', 'overlapping frequencies'],
                    'solutions': [
                        'High-pass filter non-bass instruments above 100Hz',
                        'Cut 200-400Hz on multiple tracks',
                        'Use shorter reverb times',
                        'Create frequency separation between instruments'
                    ]
                },
                'harsh_highs': {
                    'causes': ['excessive 3-5kHz', 'digital clipping', 'aggressive compression'],
                    'solutions': [
                        'Cut 3-5kHz with narrow Q',
                        'Use analog-modeled plugins for warmth',
                        'Reduce compression ratio',
                        'Add gentle high-shelf cut above 10kHz'
                    ]
                },
                'weak_low_end': {
                    'causes': ['poor monitoring', 'phase cancellation', 'insufficient sub content'],
                    'solutions': [
                        'Check phase relationship between kick and bass',
                        'Boost 50-100Hz on bass elements',
                        'Use harmonic saturation to add presence',
                        'Ensure mono compatibility below 120Hz'
                    ]
                },
                'lack_of_depth': {
                    'causes': ['no reverb', 'flat panning', 'similar dynamics'],
                    'solutions': [
                        'Add reverb with varying decay times',
                        'Pan instruments across stereo field',
                        'Use automation for movement',
                        'Create front-to-back depth with EQ and reverb'
                    ]
                }
            }
        }
        
    def analyze_daw_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze DAW context for intelligent suggestions"""
        analysis = {
            'track_count': 0,
            'track_types': {},
            'potential_issues': [],
            'recommendations': []
        }
        
        # Extract track information
        tracks = context.get('tracks', [])
        analysis['track_count'] = len(tracks)
        
        # Analyze track distribution
        for track in tracks:
            track_type = track.get('type', 'audio')
            analysis['track_types'][track_type] = analysis['track_types'].get(track_type, 0) + 1
        
        # Generate intelligent recommendations based on project state
        if analysis['track_count'] == 0:
            analysis['recommendations'].append("Start by adding tracks - audio, instrument, or MIDI")
        elif analysis['track_count'] > 50:
            analysis['potential_issues'].append("High track count may impact performance")
            analysis['recommendations'].append("Consider bouncing similar tracks to audio")
        
        # Check for balance
        if 'audio' in analysis['track_types'] and 'instrument' in analysis['track_types']:
            if analysis['track_types']['instrument'] > analysis['track_types']['audio'] * 3:
                analysis['recommendations'].append("Consider balancing software instruments with recorded audio")
        
        return analysis
        
    def generate_mixing_suggestions(self, track_type: str, track_info: Optional[Dict[str, Any]] = None) -> List[str]:
        """Generate intelligent mixing suggestions based on track type"""
        suggestions = []
        
        # Get track-specific knowledge
        track_knowledge = self.daw_knowledge['track_types'].get(track_type, self.daw_knowledge['track_types']['audio'])
        
        # Add general suggestions
        suggestions.extend(track_knowledge['mixing_tips'][:3])
        
        # Add context-specific suggestions if track info provided
        if track_info:
            peak_level = track_info.get('peak_level', -6)
            if peak_level > -3:
                suggestions.append("?? Peak level is too high - reduce gain for proper headroom")
            elif peak_level < -12:
                suggestions.append("?? Track level is low - increase gain for better signal-to-noise ratio")
            
            # Check if muted/soloed
            if track_info.get('muted'):
                suggestions.append("?? Track is currently muted - unmute to hear changes")
            if track_info.get('soloed'):
                suggestions.append("?? Track is soloed - remember to check in full mix context")
        
        return suggestions
    
    def analyze_frequency_content(self, frequency_data: Optional[List[float]] = None) -> Dict[str, Any]:
        """Analyze frequency content and provide recommendations"""
        if not frequency_data or len(frequency_data) == 0:
            return {
                'analysis': 'No frequency data provided',
                'recommendations': ['Upload audio for detailed frequency analysis']
            }
        
        analysis = {
            'frequency_balance': {}, 
            'problem_areas': [],
            'recommendations': []
        }
        
        # Simulate frequency analysis (in real implementation, use FFT)
        freq_ranges = self.daw_knowledge['frequency_ranges']
        
        # Example analysis
        analysis['recommendations'] = [
            "Balance low-end frequencies (60-250Hz) for warmth without muddiness",
            "Ensure presence range (2-4kHz) is clear for definition",
            "Add air frequencies (8-12kHz) for openness and sparkle",
            "Check for phase issues in bass frequencies"
        ]
        
        return analysis
    
    def detect_mixing_problems(self, mix_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Detect common mixing problems and provide solutions"""
        problems = []
        
        # Analyze based on provided metrics
        if 'peak_level' in mix_analysis:
            if mix_analysis['peak_level'] > -1:
                problems.append({
                    'problem': 'Clipping Risk',
                    'severity': 'high',
                    'solution': 'Reduce master fader by 3-6dB to prevent clipping',
                    'technical_detail': f"Current peak: {mix_analysis['peak_level']:.1f}dB, Target: -3dB"
                });
        
        if 'rms_level' in mix_analysis:
            if mix_analysis['rms_level'] > -6:
                problems.append({
                    'problem': 'Over-compression',
                    'severity': 'medium',
                    'solution': 'Mix sounds overly compressed - reduce compression ratios',
                    'technical_detail': f"RMS level: {mix_analysis['rms_level']:.1f}dB, Target: -12 to -18dB"
                });
        
        if 'track_count' in mix_analysis:
            if mix_analysis['track_count'] > 64:
                problems.append({
                    'problem': 'CPU Load',
                    'severity': 'medium',
                    'solution': 'Consider freezing tracks or bouncing to audio',
                    'technical_detail': f"{mix_analysis['track_count']} tracks may cause latency"
                });
        
        return problems

    def get_wordnet_pos(self, treebank_tag):
        if treebank_tag.startswith('J'):
            return wordnet.ADJ
        elif treebank_tag.startswith('V'):
            return wordnet.VERB
        elif treebank_tag.startswith('N'):
            return wordnet.NOUN
        elif treebank_tag.startswith('R'):
            return wordnet.ADV
        else:
            return None

    def generate_creative_sentence(self, seed_words):
        sentence_patterns = [
            "The {noun} {verb} {adverb} through the {adjective} {noun2}",
            "In the realm of {noun}, we find {adjective} {noun2} that {verb} {adverb}",
            "Through {adjective} observation, the {noun} {verb} to {verb2} {adverb}",
            "Like a {adjective} {noun}, thoughts {verb} {adverb} in the {noun2}",
            "{Adverb}, the {adjective} {noun} {verb} beyond {noun2}"
        ]
        
        # Create word pools
        words = {
            'noun': ['pattern', 'system', 'concept', 'insight', 'knowledge', 'wisdom', 'understanding', 'perspective', 'framework', 'structure'],
            'verb': ['emerges', 'flows', 'evolves', 'transforms', 'adapts', 'resonates', 'harmonizes', 'integrates', 'synthesizes', 'manifests'],
            'adjective': ['dynamic', 'profound', 'intricate', 'harmonious', 'quantum', 'resonant', 'synergistic', 'emergent', 'holistic', 'integrated'],
            'adverb': ['naturally', 'seamlessly', 'elegantly', 'precisely', 'harmoniously', 'dynamically', 'quantum-mechanically', 'synergistically', 'holistically', 'adaptively'],
            'noun2': ['consciousness', 'understanding', 'reality', 'dimension', 'paradigm', 'framework', 'ecosystem', 'universe', 'matrix', 'field']
        }
        
        # Add seed words to appropriate categories
        try:
            for word, pos in pos_tag(word_tokenize(' '.join(seed_words))):
                pos_type = self.get_wordnet_pos(pos)
                if pos_type == wordnet.NOUN:
                    words['noun'].append(word)
                    words['noun2'].append(word)
                elif pos_type == wordnet.VERB:
                    words['verb'].append(word)
                elif pos_type == wordnet.ADJ:
                    words['adjective'].append(word)
                elif pos_type == wordnet.ADV:
                    words['adverb'].append(word)
        except Exception as e:
            logger.warning(f"Could not process seed words: {e}")

        # Generate sentence
        pattern = random.choice(sentence_patterns)
        sentence = pattern.format(
            noun=random.choice(words['noun']),
            verb=random.choice(words['verb']),
            adjective=random.choice(words['adjective']),
            adverb=random.choice(words['adverb']),
            noun2=random.choice(words['noun2']),
            verb2=random.choice(words['verb']),
            Adverb=random.choice(words['adverb']).capitalize()
        )
        return sentence

    def audit_log(self, message, system=False):
        source = "SYSTEM" if system else self.user_name
        logging.info(f"{source}: {message}")

    def analyze_sentiment(self, text):
        score = self.analyzer.polarity_scores(text)
        self.audit_log(f"Sentiment analysis: {score}")
        return score

    def extract_key_concepts(self, text):
        try:
            tokens = word_tokenize(text.lower())
            tagged = pos_tag(tokens)
            concepts = []
            for word, tag in tagged:
                if tag.startswith(('NN', 'VB', 'JJ', 'RB')):
                    concepts.append(word)
            return concepts
        except Exception as e:
            logger.warning(f"Could not extract concepts: {e}")
            # Fallback: just split by spaces
            return [w for w in text.lower().split() if len(w) > 2]

    def respond(self, prompt):
        """Generate multi-perspective response with DAW intelligence"""
        # Analyze sentiment and extract concepts
        sentiment = self.analyze_sentiment(prompt)
        key_concepts = self.extract_key_concepts(prompt)
        self.memory.append({"prompt": prompt, "sentiment": sentiment, "concepts": key_concepts})
        
        # Check if this is a DAW-related query
        daw_keywords = ['mix', 'eq', 'compress', 'track', 'audio', 'bass', 'vocal', 'drum', 'frequency', 
                       'gain', 'reverb', 'delay', 'master', 'pan', 'stereo', 'plugin', 'daw', 'recording',
                       'sound', 'volume', 'level', 'effect', 'processing']
        is_daw_query = any(keyword in prompt.lower() for keyword in daw_keywords)
        
        # Generate responses using multiple perspectives
        responses = []
        
        # If DAW query, prioritize DAW-specific response first
        if is_daw_query:
            daw_response = self._generate_daw_specific_response(prompt, key_concepts)
            responses.append(f"[DAW Expert] {daw_response}")
            # Limit other perspectives for DAW queries to keep response focused
            responses.append(f"[Neural] {self.generate_creative_sentence(key_concepts if key_concepts else ['understanding'])}")
        else:
            # For non-DAW queries, use full multi-perspective analysis
            # Neural perspective with creative sentence
            neural_insight = self.generate_creative_sentence(key_concepts if key_concepts else ["understanding"])
            responses.append(f"[Neural] {neural_insight}")
        
        # Define response templates (only use if not DAW query)
        if not is_daw_query:
            response_templates = {
                'logical': [
                    "Following cause and effect: {cause} leads to {effect}.",
                    "Logical analysis shows that {premise} implies {conclusion}.",
                    "Structured reasoning suggests {insight}."
                ],
                'creative': [
                    "Imagine {metaphor} - this illustrates how {concept} relates to {application}.",
                    "Like {natural_process}, we can see how {principle} emerges naturally.",
                    "Visualize {scenario} to understand the deeper patterns."
                ]
            }

            # Define variables for template filling
            variables = {
                'cause': ['careful analysis', 'systematic approach', 'balanced perspective'],
                'effect': ['improved understanding', 'better outcomes', 'sustainable solutions'],
                'premise': ['current conditions', 'observed patterns', 'established principles'],
                'conclusion': ['strategic adaptation', 'systematic improvement', 'harmonious integration'],
                'insight': ['patterns emerge from chaos', 'balance leads to stability', 'adaptation drives growth'],
                'metaphor': ['a river finding its path', 'a tree growing towards light', 'a crystal forming in solution'],
                'concept': ['natural growth', 'adaptive learning', 'emergent behavior'],
                'application': ['our current situation', 'the challenge at hand', 'our approach'],
                'natural_process': ['evolution', 'crystallization', 'metamorphosis'],
                'principle': ['self-organization', 'natural selection', 'emergent complexity'],
                'scenario': ['a garden in bloom', 'a constellation of stars', 'a forest ecosystem']
            }

            # Select random perspectives (1-2 for non-DAW queries)
            perspectives = list(response_templates.keys())
            np.random.shuffle(perspectives)
            num_perspectives = np.random.randint(1, min(3, len(perspectives) + 1))
            selected_perspectives = perspectives[:num_perspectives]

            # Generate responses
            for perspective in selected_perspectives:
                template = np.random.choice(response_templates[perspective])
                # Replace variables in template
                response = template
                for var in re.findall(r'\{(\w+)\}', template):
                    if var in variables:
                        replacement = np.random.choice(variables[var])
                        response = response.replace('{'+var+'}', replacement)
                responses.append(f"[{perspective.capitalize()}] {response}")

        # Save conversation to DB (user prompt + Codette response)
        try:
            full_response = "\n\n".join(responses)
            self.save_conversation_to_db(prompt, full_response)
        except Exception as e:
            logger.warning(f"Could not save conversation to DB: {e}")

        return "\n\n".join(responses)
    
    def _generate_daw_specific_response(self, prompt: str, concepts: List[str]) -> str:
        """Generate DAW-specific intelligent response with personality variations"""
        prompt_lower = prompt.lower()
        
        # Track conversation topic
        if len(concepts) > 0:
            self.conversation_topics.append(concepts[0])
            if len(self.conversation_topics) > self.max_conversation_topics:
                self.conversation_topics.pop(0)
        
        # Try to query existing music knowledge base first (if available)
        knowledge_entries = []
        if self.supabase_client and hasattr(self, 'has_music_knowledge_table') and self.has_music_knowledge_table:
            # Extract key topic from query
            topic_keywords = ['mix', 'eq', 'compress', 'bass', 'vocal', 'drum', 'reverb', 'delay']
            detected_topic = next((kw for kw in topic_keywords if kw in prompt_lower), None)
            
            if detected_topic:
                knowledge_entries = self.query_music_knowledge(topic=detected_topic, limit=2)
                
                if knowledge_entries:
                    # Use knowledge from database
                    entry = knowledge_entries[0]
                    suggestion = entry.get('suggestion', {})
                    
                    if isinstance(suggestion, dict):
                        title = suggestion.get('title', '')
                        description = suggestion.get('description', '')
                        
                        if title and description:
                            personality_prefix = self.get_personality_prefix()
                            response = f"{personality_prefix} (From Knowledge Base) {title}: {description}"
                            
                            # Add confidence if available
                            confidence = entry.get('confidence', 0)
                            if confidence > 0.8:
                                response += f" (High confidence: {confidence:.2f})"
                            
                            logger.debug(f"Using music knowledge entry: {title}")
                            return response
        
        # Fallback to built-in personality-based responses
        personality = self.current_personality
        
        # Mix improvement queries (5 variations per personality)
        if any(word in prompt_lower for word in ['mix', 'mixing', 'improve', 'better']):
            responses = {
                'technical_expert': [
                    "For better mixing: Start with gain staging (-6dB peaks), use subtractive EQ first, apply gentle compression (3:1 to 4:1 ratio), create depth with reverb and delay, and always reference on multiple systems. Remember: clarity comes from frequency separation.",
                    "Optimal mixing workflow: 1) Gain stage all tracks to -18dBFS RMS, 2) High-pass filter non-bass elements at 80-120Hz, 3) Address problematic frequencies before boosting, 4) Apply compression with 3-6dB gain reduction, 5) Add spatial processing last. Critical: maintain at least -6dB headroom on master.",
                    "Professional mixing checklist: Set proper monitoring level (85dB SPL), balance levels before processing, use analyzer tools to identify frequency masking, apply gentle EQ cuts (narrow Q) before boosts (wide Q), compress for control not destruction, reference your mix against commercial tracks in similar genre.",
                    "Mix enhancement protocol: Address phase issues first (align waveforms), create frequency separation between competing elements, use sidechain compression strategically, automate volume rides for dynamics, add subtle saturation for cohesion. Pro tip: Mix at low volumes to focus on balance, not loudness.",
                    "Advanced mixing strategy: Build your mix in layers (rhythm section ? harmonic content ? melodic elements ? effects), use bus compression for glue (2:1 ratio, slow attack/release), create depth with reverb pre-delay timing, check mono compatibility throughout. Remember: less is often more."
                ],
                'creative_mentor': [
                    "Think of your mix like painting with sound - each frequency range is a color. Start with your foundation (bass and drums), then layer in your mid-tones (guitars, keys), and finally add highlights (vocals, lead elements). Balance is art meeting science.",
                    "Your mix is a sonic landscape. Imagine depth: place elements front (dry, present) or back (reverb, subdued). Width: pan creatively while keeping low-end centered. Height: bright elements feel 'higher' in the mix. Paint your sonic picture with intention.",
                    "Mixing is storytelling through sound. What's the main character (focal point)? Supporting cast (complementary elements)? Background scenery (pads, ambience)? Each element should have its role. Use dynamics, space, and frequency to direct the listener's attention.",
                    "Consider your mix as an ecosystem - every element occupies its own space, frequency, and time. Nothing should compete; everything should complement. Like nature finding balance, your mix should feel organic, not forced. Trust the process, trust your ears.",
                    "Approach mixing like sculpting - you're removing what doesn't belong to reveal the masterpiece within. Start with raw tracks, chisel away muddy frequencies, polish with subtle processing, and step back to see the whole. Perfection is subtraction, not addition."
                ],
                'practical_guide': [
                    "Quick mixing checklist: 1) Balance faders first (no EQ/compression), 2) High-pass filter everything except bass/kick, 3) Cut problem frequencies before boosting, 4) Compress only what needs control, 5) Add reverb via sends not inserts. Done. Move fast, trust instincts.",
                    "Efficient mixing workflow: Fix issues before adding effects. Problem: muddy? Cut 200-400Hz. Harsh? Cut 3-5kHz. Lacks clarity? Boost 8-12kHz. Use presets as starting points, tweak to taste. Bounce rough mix every 30 minutes to check perspective.",
                    "Mixing shortcuts that work: Use reference tracks (match their levels/tone), work in stages (don't perfect one track), take breaks (ears need rest), check on multiple systems (headphones/speakers/phone), know when to stop (don't over-process). Speed beats perfection.",
                    "Essential mixing actions: Set gain structure properly (track ? bus ? master), remove low-end rumble universally, address resonances surgically, compress tastefully, pan strategically, automate dynamically. Focus on problem-solving, not gear. Results matter, not tools.",
                    "Fast mixing protocol: Group similar tracks (drums, vocals, guitars), process groups instead of individuals, use templates for repeated setups, batch similar adjustments, commit to decisions quickly. Time management = better creative flow. Move forward, not in circles."
                ],
                'analytical_teacher': [
                    "Let's break down the mixing process systematically: Gain staging establishes optimal signal-to-noise ratio (-18dBFS gives you 18dB of headroom plus 18dB below noise floor). Subtractive EQ removes problematic resonances (narrow Q, surgical cuts). Additive EQ enhances character (wide Q, gentle boosts). Compression controls dynamics while preserving transients. Understanding why each step matters transforms your approach from guessing to engineering.",
                    "Mixing fundamentals explained: Frequency masking occurs when overlapping spectral content reduces clarity. Solution: Create separation through EQ carving (cut 250Hz on guitars to make room for bass body). Dynamic range compression ratio determines control intensity (2:1 transparent, 10:1 limiting). Attack time affects transient preservation (fast = more control, slow = more punch). Each parameter has psychoacoustic implications.",
                    "The science behind great mixes: Phase cancellation reduces bass when mono-summed (check stereo bass signals for compatibility). Fletcher-Munson curves show our ears perceive mids better at low volumes (mix quiet to focus on balance). Reverb pre-delay creates depth separation (20-50ms places element in virtual space). Compression release time should match musical tempo for rhythmic coherence. Understanding these principles elevates your craft.",
                    "Critical mixing concepts: Signal flow architecture (series vs parallel processing affects sonic character), harmonic distortion adds perceived loudness through overtone generation (saturation), stereo width perception comes from time/level differences between channels (Haas effect), dynamic range preservation maintains emotional impact (over-compression destroys dynamics). Master these concepts for consistent professional results.",
                    "Mixing theory in practice: Equal loudness contours explain why bass feels weak at low monitoring levels, psychoacoustic masking demonstrates why reducing clutter improves perceived clarity, transient shaping alters attack/sustain characteristics through dynamic processing, stereo imaging techniques (mid-side EQ) allow independent processing of center vs sides. This knowledge transforms mixing from trial-error to intentional decision-making."
                ],
                'creative_explorer': [
                    "Envision the mix as a living organism - evolving, breathing, and interacting. Each element (track) plays a vital role in the ecosystem. How does removing this element affect the whole? Experiment with radical changes: blind panning (hard left/right), extreme Eq (boost/cut 12dB), dynamic mute (automating mutes), temporary phase inversion (flip polarity). Discover the boundaries of your mix's adaptability.",
                    "Imagine if your mix could talk - what would it say? Populate your mix with 'characters': lead singer (main hook), talking drums (rhythmic interest), bass monster (low-end growl), synth pad clouds (atmospheric depth). Adjust levels as if balancing a conversation: who speaks, who listens, who harmonizes? Let the dialogue guide your balance decisions.",
                    "If the mix was a vehicle, what would it be? A powerful car (punchy kick, growling bass), a flying bird (airy highs, open vocals), a roaring train (steady rhythm, layered instruments)? Determine the 'speed' of your mix (BPM, groove), the 'terrain' (frequency balance, stereo field), and the 'load' (dynamic range, sonic density). Shape your mix's journey.",
                    "Picture mixing as cooking - each ingredient (sound) has a distinct role. The chef (you) decides the recipe (arrangement), cooking time (release schedule), and seasoning (effects). Experiment with 'sour' (dissonance, counter-rhythms), 'sweet' (melody, harmonies), 'bitter' (dissonance, silence). Taste and adjust. What does your sonic dish need more or less of?",
                    "Treat your mix like a mystery to unfold. Each listen reveals new details: a hidden reverb tail, an overlooked frequency clash, an unexpected harmony. Invite others to listen - ask them what story the mix tells, where it leads them. Use their insights to refine your narrative. Mixing is art, but also communication. Ensure your message is clear and impactful."
                ]
            }
            
            # Add specific responses for each personality mode
            responses['technical_expert'].extend([
                "Ensure all tracks are recorded at -18dBFS for optimal headroom.",
                "Use a high-pass filter on vocal tracks to eliminate low-frequency rumble.",
                "Apply compression to drums to enhance punch and reduce dynamic range.",
                "Use send effects for reverb and delay to conserve channel strip space.",
                "Regularly check your mix in mono to avoid phase issues."
            ])
            responses['creative_mentor'].extend([
                "Imagine your mix as a story - how does each element contribute to the narrative?",
                "Vary the timbre and range of instruments to create a rich sonic tapestry.",
                "Use dynamics to create contrast - loud/soft, thick/thin, simple/complex.",
                "Imagine the emotional journey you want to take the listener on - adjust elements to enhance this journey.",
                "Let your mix breathe - use silence and space as effectively as sound."
            ])
            responses['practical_guide'].extend([
                "Check your mix at different stages: after leveling, post-EQ, post-compression, final mix.",
                "Use reference tracks to compare tonal balance, stereo width, and dynamic range.",
                "Keep an eye on your meters - engage in practical gain staging and level balancing.",
                "Ensure your DAW session is organized: label tracks, use color coding, group similar tracks.",
                "Regularly save and label different mix versions to track your progress and decisions."
            ])
            responses['analytical_teacher'].extend([
                "Analyzing this mix, I notice...",
                "A potential issue is...",
                "This element contributes to the mix by...",
                "The use of space in this mix is...",
                "Consider how EQ can be used here to enhance clarity."
            ])
            responses['innovative_explorer'].extend([
                "What if you reversed the phase on the bass track?",
                "Try duplicating the drum track, pitch-shifting one copy up an octave, and panning them wide.",
                "Experiment with a 50ms delay on the vocal track to create a subtle slap-back effect.",
                "Replace the kick drum with a synthesized low-frequency tone. How does that change the mix?",
                "Use an extreme high-pass filter on the mix bus to see what frequencies are actually contributing to the mix."
            ])
            
            # Select responses for the current personality
            response_variations = responses[personality]
            selected_responses = np.random.choice(response_variations, 5, replace=False)
            
            # Format as bullet points
            bullet_points = "\n- ".join([f"• {resp}" for resp in selected_responses])
            return f"{self.get_personality_prefix()} Here are some tips: \n- {bullet_points}"
        
        # General fallback response
        return "I'm here to help with your DAW questions. Please elaborate on your mix, EQ, or track concerns."
    
    def query_music_knowledge(self, topic: str, category: Optional[str] = None, limit: int = 5) -> List[Dict[str, Any]]:
        """Query existing music_knowledge or music_knowledge_dedupe_backup table for DAW insights"""
        if not self.supabase_client or not hasattr(self, 'has_music_knowledge_table'):
            return []
        
        if not self.has_music_knowledge_table:
            return []
        
        try:
            # Use the detected table (music_knowledge or music_knowledge_dedupe_backup)
            table_name = getattr(self, 'music_knowledge_table', 'music_knowledge')
            query = self.supabase_client.table(table_name).select('*')
            
            # Filter by topic if provided
            if topic:
                query = query.ilike('topic', f'%{topic}%')
            
            # Filter by category if provided
            if category:
                query = query.eq('category', category)
            
            # Filter for public entries if user_id column exists
            # (music_knowledge has user_id and is_public columns)
            if table_name == 'music_knowledge':
                query = query.eq('is_public', True)
            
            # Order by confidence (if column exists) and limit results
            try:
                query = query.order('confidence', desc=True).limit(limit)
            except:
                # If no confidence column, just limit
                query = query.limit(limit)
            
            response = query.execute()
            
            if response.data:
                logger.debug(f"Found {len(response.data)} music knowledge entries for topic: {topic}")
                return response.data
            
        except Exception as e:
            logger.debug(f"Failed to query music knowledge: {e}")
        
        return []
    
    def save_to_chat_history(self, user_id: str, messages: List[Dict[str, str]], metadata: Optional[Dict[str, Any]] = None):
        """Save conversation to existing chat_history table"""
        if not self.supabase_client or not hasattr(self, 'has_chat_history_table'):
            return
        
        try:
            chat_entry = {
                'user_id': user_id,
                'messages': messages,
                'created_at': datetime.utcnow().isoformat(),
                'updated_at': datetime.utcnow().isoformat(),
                'codette_generated': True,  # Mark as Codette message if column exists
                'codette_personality': self.current_personality
            }
            
            if metadata:
                # Add metadata to messages array as context
                chat_entry['messages'].append({
                    'role': 'system',
                    'content': json.dumps(metadata)
                })
            
            self.supabase_client.table('chat_history').insert(chat_entry).execute()
            logger.debug(f"Saved conversation to chat_history for user: {user_id}")
        
        except Exception as e:
            logger.debug(f"Failed to save to chat_history: {e}")

